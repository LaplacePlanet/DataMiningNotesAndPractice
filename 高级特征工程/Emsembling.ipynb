{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Examined ensemble methods\n",
    "- Averaging (or blending)\n",
    "- Weighted averaging\n",
    "- Conditional averaging\n",
    "- Bagging\n",
    "- Boosting\n",
    "- Stacking\n",
    "- StackNet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Averaging ensemble methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "举个例子，假设我们有一个名为age的变量，就像年龄一样，我们试着预测它。我们有两个模型：\n",
    "- 低于50，模型效果更好\n",
    "![model1](img/model1.png)\n",
    "- 高于50，模型效果更好\n",
    "![model2](img/model2.png)\n",
    "\n",
    "那么如果我们试图结合它们将会发生什么呢？\n",
    "\n",
    "**Averaging(or blending)**<br>\n",
    "- **(model1 + model2) / 2**\n",
    "![model12](img/model12.png)\n",
    "\n",
    "$R^2$上升到0.95，较之前有所改善。但该模型并没有比单模型做的好的地方更好，尽管如此，它平均表现更好。也许可能会有更好的组合呢？来试试加权平均\n",
    "\n",
    "**Weighted averaging**<br>\n",
    "- **(model1 x 0.7 + model 2 x 0.3)**\n",
    "![model_weight](img/model_weight.png)\n",
    "看起来没有之前的好\n",
    "\n",
    "**Conditional averaging**<br>\n",
    "- **各取好的部分**\n",
    "![model_best](img/model_best.png)\n",
    "理想情况下，我们希望得到类似的结果"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bagging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Why Bagging\n",
    "建模中有两个主要误差来源\n",
    "- 1.由于偏差而存在误差（underfitting）\n",
    "- 2.由于方差而存在误差（overfitting）\n",
    "\n",
    "通过略微不同的模型，确保预测不会有读取非常高的方差。这通常使它更具普遍性。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameters that control bagging?\n",
    "- Changing the seed\n",
    "- Row(Sub) sampling or Bootstrapping\n",
    "- Shuffling\n",
    "- Column(Sub) sampling\n",
    "- Model-specific parameters\n",
    "- Number of models (or bags)\n",
    "- (Optionally) parallelism"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Examples of bagging\n",
    "![bagging_code](img/bagging_code.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Boosting\n",
    "Boosting是对每个模型构建的模型进行加权平均的一种形式，顺序地考虑以前的模型性能。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Weight based boosting\n",
    "![weight_base](img/weight_based.png)\n",
    "假设我们有一个表格数据集，有四个特征。 我们称它们为x0，x1，x2和x3，我们希望使用这些功能来预测目标变量y。\n",
    "我们将预测值称为pred，这些预测有一定的误差。我们可以计算这些绝对误差，`|y - pred|`。我们可以基于此生成一个新列或向量，在这里我们创建一个权重列，使用1加上绝对误差。当然有不同的方法来计算这个权重，现在我们只是以此为例。\n",
    "\n",
    "所有接下来要做的是用这些特征去拟合新的模型，但每次也要增加这个权重列。这就是按顺序添加模型的方法。\n",
    "\n",
    "#### Weight based boosting parameters\n",
    "- Learning rate (or shrinkage or eta)\n",
    " - 每个模型只相信一点点：`predictionN = pred0*eta + pred1*eta + ... + predN*eta`\n",
    "- Number of estimators\n",
    " - estimators扩大一倍，eta减小一倍\n",
    "- Input model - can be anything that accepts weights\n",
    "- Sub boosting type:\n",
    " - AdaBoost-Good implementation in sklearn(python)\n",
    " - LogitBoost-Good implementation in Weka(Java)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Residual based boosting [&]\n",
    "我们使用同样的数据集做相同的事。预测出pred后\n",
    "![residual_pred](img/residual_pred.png)\n",
    "接下来会计算误差\n",
    "![residual_error](img/residual_error.png)\n",
    "将error作为新的y得到新的预测new_pred\n",
    "![residual_new_pred](img/residual_new_pred.png)\n",
    "以Rownum=1为例：<br>\n",
    "最终预测=0.75 + 0.20 = 0.95更接近于1\n",
    "\n",
    "这种方法很有效，可以很好的减小误差。\n",
    "\n",
    "#### Residual based boosting parameters\n",
    "- Learning rate (or shrinkage or eta)\n",
    " - `predictionN = pred0 + pred1*eta + ... + predN*eta`\n",
    " - 前面的例子，如果eta为0.1，则Prediction=0.75 + 0.2*(0.1) = 0.77\n",
    "- Number of estimators\n",
    "- Row (sub)sampling\n",
    "- Column (sub)sampling\n",
    "- Input model - better be trees.\n",
    "- Sub boosting type:\n",
    " - Full gradient based\n",
    " - Dart\n",
    "\n",
    "#### Residual based favourite implementations\n",
    "- Xgboost\n",
    "- Lightgbm\n",
    "- H2O's GBM\n",
    "- Catboost\n",
    "- Sklearn's GBM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stacking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Methodology\n",
    "- Wolpert in 1992 introduced stacking. It involves:\n",
    " - 1. **Splitting** the train set into two disjoint sets.\n",
    " - 2. **Train** several base learners on the first part.\n",
    " - 3. **Make predictions** with the base learners on the second (validation) part."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 具体步骤\n",
    "假设有A,B,C三个数据集，其中A,B的目标变量y已知。\n",
    "![stacking_data](img/stacking_data.png)\n",
    "然后\n",
    "- 算法0拟合A，预测B和C，然后保存pred0到B1,C1\n",
    "- 算法1拟合A，预测B和C，然后保存pred1到B1,C1\n",
    "- 算法2拟合A，预测B和C，然后保存pred2到B1,C1\n",
    "![stacking_data2](img/stacking_data2.png)\n",
    "- 算法3拟合B1，预测C1，得到最终结果preds3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stacking example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "``` Python\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "train = '' # your training set\n",
    "y = ''     # your target variable\n",
    "# split train data in 2 part, training and valdiation.\n",
    "training, valid, ytraining, yvalid = train_test_split(train, y, test_size=0.5)\n",
    "# specify models\n",
    "model1 = RandomForestRegressor()\n",
    "model2 = LinearRegression()\n",
    "#fit models\n",
    "model1.fit(training, ytraining)\n",
    "model2.fit(trainging, ytraining)\n",
    "# make predictions for validation\n",
    "preds1 = model1.predict(valid)\n",
    "preds2 = model2.predict(valid)\n",
    "# make predictions for test data\n",
    "test_preds1 = model1.predict(test)\n",
    "test_preds2 = model2.predict(test)\n",
    "# From a new dataset for valid and test via stacking the predictions\n",
    "stacked_predictions = np.colum_stack((preds1, preds2))\n",
    "stacked_test_predictions = np.column_stack((test_preds1, test_preds2))\n",
    "# specify meta model\n",
    "meta_model = LinearRegression()\n",
    "meta_model.fit(stacked_predictions, yvalid)\n",
    "# make predictions on the stacked predictions of the test data\n",
    "final_predictions = meta_model.predict(stacked_test_predictions)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stacking(past) example\n",
    "![stacking_past](img/stacking_past.png)\n",
    "\n",
    "可以看到，它与我们使用`Conditional averaging`的结果非常近似。只是在50附件做的不够好，这是有道理的，因为模型没有见到目标变量，无法准确识别出50这个缺口。所以它只是尝试根据模型的输入来确定。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Things to be mindful of\n",
    "- With time sensitive data - respect time \n",
    " - 如果你的数据带有时间元素，你需要指定你的stacking，以便尊重时间。\n",
    "- Diversity as important as performance\n",
    " - 单一模型表现很重要，但模型的多样性也非常重要。当模型是坏的或弱的情况，你不需太担心，stacking实际上可以从每个预测中提取到精华，得到好的结果。因此，你真正需要关注的是，我正在制作的模型能给我带来哪些信息，即使它通常很弱。\n",
    "- Diversity may come from:\n",
    " - Different algorithms\n",
    " - Different input features\n",
    "- Performance plateauing after N models\n",
    "- Meta model is normally modest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## StackNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
