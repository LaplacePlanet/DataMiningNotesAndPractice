{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "pd.set_option('display.max_columns', 100)\n",
    "pd.set_option('display.max_rows', 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "homePath = \"data\"\n",
    "trainDataPath = os.path.join(homePath, \"train.csv\")\n",
    "testDataPath = os.path.join(homePath, \"test.csv\")\n",
    "trainData = pd.read_csv(trainDataPath)\n",
    "testData = pd.read_csv(testDataPath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "652936"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# y = trainData['y']\n",
    "# trainData.drop('y', axis=1, inplace=True)\n",
    "# trainData = pd.concat([trainData, testData], axis=0, ignore_index=True)\n",
    "len(trainData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/heolis/anaconda3/envs/tensorflow/lib/python3.5/site-packages/ipykernel_launcher.py:3: FutureWarning: reshape is deprecated and will raise in a subsequent release. Please use .values.reshape(...) instead\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "/home/heolis/anaconda3/envs/tensorflow/lib/python3.5/site-packages/ipykernel_launcher.py:4: FutureWarning: reshape is deprecated and will raise in a subsequent release. Please use .values.reshape(...) instead\n",
      "  after removing the cwd from sys.path.\n",
      "/home/heolis/anaconda3/envs/tensorflow/lib/python3.5/site-packages/ipykernel_launcher.py:5: FutureWarning: reshape is deprecated and will raise in a subsequent release. Please use .values.reshape(...) instead\n",
      "  \"\"\"\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "est = KMeans(n_clusters=5, init=\"k-means++\", n_jobs=-1)\n",
    "est.fit(trainData['district_id'].reshape(-1, 1))\n",
    "trainData['district_id'] = est.predict(trainData['district_id'].reshape(-1, 1))\n",
    "testData['district_id'] = est.predict(testData['district_id'].reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/heolis/anaconda3/envs/tensorflow/lib/python3.5/site-packages/ipykernel_launcher.py:2: FutureWarning: reshape is deprecated and will raise in a subsequent release. Please use .values.reshape(...) instead\n",
      "  \n",
      "/home/heolis/anaconda3/envs/tensorflow/lib/python3.5/site-packages/ipykernel_launcher.py:3: FutureWarning: reshape is deprecated and will raise in a subsequent release. Please use .values.reshape(...) instead\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "/home/heolis/anaconda3/envs/tensorflow/lib/python3.5/site-packages/ipykernel_launcher.py:4: FutureWarning: reshape is deprecated and will raise in a subsequent release. Please use .values.reshape(...) instead\n",
      "  after removing the cwd from sys.path.\n"
     ]
    }
   ],
   "source": [
    "est = KMeans(n_clusters=5, init=\"k-means++\", n_jobs=-1)\n",
    "est.fit(trainData['area_id'].reshape(-1, 1))\n",
    "trainData['area_id'] = est.predict(trainData['area_id'].reshape(-1, 1))\n",
    "testData['area_id'] = est.predict(testData['area_id'].reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "index = trainData['floors_before'] >= trainData['floors_after']\n",
    "trainData = trainData[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "index = trainData['age'] <= 176\n",
    "trainData = trainData[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "index = trainData['height_after'] <= trainData['height_before']\n",
    "trainData = trainData[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "index = trainData['height_before'] < 50\n",
    "trainData = trainData[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "land_condition = trainData['land_condition']\n",
    "foundation_type = trainData['foundation_type']\n",
    "roof_type = trainData['roof_type']\n",
    "ground_floor_type = trainData['ground_floor_type']\n",
    "\n",
    "trainData = pd.get_dummies(trainData, columns=['position', 'land_condition', 'foundation_type', 'roof_type', 'ground_floor_type'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "land_condition.replace(['F', 'M', 'S'], [1, 2, 3], inplace=True)\n",
    "foundation_type.replace(['M', 'C', 'R', 'B', 'O'], [5, 4, 3, 2, 1], inplace=True)\n",
    "roof_type.replace(['L', 'H', 'R'], [3, 2, 1], inplace=True)\n",
    "ground_floor_type.replace(['M', 'R', 'B', 'T', 'O'], [5, 4, 3, 2, 1], inplace=True)\n",
    "trainData['4_rebuild'] = land_condition + foundation_type + roof_type + ground_floor_type\n",
    "trainData['l_f'] = land_condition + foundation_type\n",
    "trainData['l_r'] = land_condition + roof_type\n",
    "trainData['l_g'] = land_condition + ground_floor_type\n",
    "trainData['f_r'] = foundation_type + roof_type\n",
    "trainData['f_g'] = foundation_type + ground_floor_type\n",
    "trainData['r_g'] = roof_type + ground_floor_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "land_condition = testData['land_condition']\n",
    "foundation_type = testData['foundation_type']\n",
    "roof_type = testData['roof_type']\n",
    "ground_floor_type = testData['ground_floor_type']\n",
    "\n",
    "testData = pd.get_dummies(testData, columns=['position', 'land_condition', 'foundation_type', 'roof_type', 'ground_floor_type'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "land_condition.replace(['F', 'M', 'S'], [1, 2, 3], inplace=True)\n",
    "foundation_type.replace(['M', 'C', 'R', 'B', 'O'], [5, 4, 3, 2, 1], inplace=True)\n",
    "roof_type.replace(['L', 'H', 'R'], [3, 2, 1], inplace=True)\n",
    "ground_floor_type.replace(['M', 'R', 'B', 'T', 'O'], [5, 4, 3, 2, 1], inplace=True)\n",
    "testData['4_rebuild'] = land_condition + foundation_type + roof_type + ground_floor_type\n",
    "testData['l_f'] = land_condition + foundation_type\n",
    "testData['l_r'] = land_condition + roof_type\n",
    "testData['l_g'] = land_condition + ground_floor_type\n",
    "testData['f_r'] = foundation_type + roof_type\n",
    "testData['f_g'] = foundation_type + ground_floor_type\n",
    "testData['r_g'] = roof_type + ground_floor_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trainData['per_floor_height_before'] = trainData['height_before'] / trainData['floors_before']\n",
    "trainData['per_floor_height_after'] = trainData['height_after'] / trainData['floors_after']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "testData['per_floor_height_before'] = testData['height_before'] / testData['floors_before']\n",
    "testData['per_floor_height_after'] = testData['height_after'] / testData['floors_after']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trainData[\"age_area\"] = trainData['age'] / trainData['area']\n",
    "testData[\"age_area\"] = testData['age'] / testData['area']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trainData.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trainData.drop('id', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "testData.fillna(0, inplace=True)\n",
    "testData.drop('id', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import lightgbm as lgb\n",
    "\n",
    "params = {\n",
    "    'learning_rate':0.1,\n",
    "    'lambda_l1':0.1,\n",
    "    'lambda_l2':0.2,\n",
    "    'max_depth':4,\n",
    "    'objective':'multiclass',\n",
    "    'num_class':4\n",
    "}\n",
    "\n",
    "lgb_train = lgb.Dataset(train[:600000], y[:600000])\n",
    "lgb_eval = lgb.Dataset(train[600000:], y[600000:])\n",
    "gbm = lgb.train(params,\n",
    "                lgb_train,\n",
    "                num_boost_round=20,\n",
    "                valid_sets=lgb_eval,\n",
    "                early_stopping_rounds=5)\n",
    "lgb.plot_importance(gbm, figsize=(10,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "per_floor_height_after     -0.517127\n",
       "height_after               -0.443536\n",
       "floors_after               -0.405705\n",
       "ground_floor_type_R        -0.382114\n",
       "roof_type_R                -0.331644\n",
       "foundation_type_R          -0.314671\n",
       "foundation_type_B          -0.205903\n",
       "area_id                    -0.175130\n",
       "foundation_type_C          -0.172373\n",
       "area                       -0.149299\n",
       "per_floor_height_before    -0.146806\n",
       "district_id                -0.085735\n",
       "position_Not attached      -0.049879\n",
       "foundation_type_O          -0.030112\n",
       "land_condition_F           -0.023559\n",
       "ground_floor_type_O        -0.022835\n",
       "ground_floor_type_T        -0.016830\n",
       "position_Attached-2 side   -0.012019\n",
       "ground_floor_type_B         0.002914\n",
       "land_condition_M            0.016435\n",
       "position_Attached-3 side    0.017995\n",
       "land_condition_S            0.018032\n",
       "position_Attached-1 side    0.058592\n",
       "roof_type_H                 0.082415\n",
       "height_before               0.094980\n",
       "roof_type_L                 0.097213\n",
       "l_g                         0.156026\n",
       "l_r                         0.174592\n",
       "floors_before               0.192760\n",
       "age_area                    0.202228\n",
       "age                         0.222218\n",
       "r_g                         0.244821\n",
       "ground_floor_type_M         0.283176\n",
       "l_f                         0.336764\n",
       "4_rebuild                   0.365961\n",
       "f_r                         0.373940\n",
       "f_g                         0.375418\n",
       "foundation_type_M           0.414113\n",
       "y                           1.000000\n",
       "Name: y, dtype: float64"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corr = trainData.corr()\n",
    "corr['y'].sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def test_score(y1, y2, trueLabels):\n",
    "    pred_score = (y1 == trueLabels).sum() / len(trueLabels)\n",
    "    pred_score += (y2 == trueLabels).sum() * 0.5 / len(trueLabels)\n",
    "    return pred_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = trainData.copy()\n",
    "\n",
    "y = train['y']\n",
    "train.drop('y', axis=1, inplace=True)\n",
    "\n",
    "# from sklearn.decomposition import PCA\n",
    "# pca = PCA(n_components=14)\n",
    "# pca.fit(train)\n",
    "# print(pca.n_components_, pca.explained_variance_ratio_)\n",
    "# train = pca.transform(train)\n",
    "# test = pca.transform(testData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test = testData"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "xgb_model = xgb.XGBClassifier(objective='multi:softmax',\n",
    "                              eval_metric=['map@2', 'merror'],\n",
    "                              n_estimators=700,\n",
    "                              num_class=4,\n",
    "                              silent=1,\n",
    "                              max_depth=6,\n",
    "                              nthread=4,\n",
    "                              learning_rate=0.1,\n",
    "                              gamma=0.5,\n",
    "                              min_child_weight=0.6,\n",
    "                              max_delta_step=0.1,\n",
    "                              subsample=0.6,\n",
    "                              colsample_bytree=0.7,\n",
    "                              reg_lambda=0.4,\n",
    "                              reg_alpha=0.8,\n",
    "                              num_leaves=250,\n",
    "                              early_stopping_rounds=20,\n",
    "                              num_boost_round=8000,\n",
    "                              scale_pos_weight=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=0.7, early_stopping_rounds=20,\n",
       "       eval_metric=['map@2', 'merror'], gamma=0.5, learning_rate=0.1,\n",
       "       max_delta_step=0.1, max_depth=6, min_child_weight=0.6, missing=None,\n",
       "       n_estimators=700, n_jobs=1, nthread=4, num_boost_round=8000,\n",
       "       num_class=4, num_leaves=250, objective='multi:softprob',\n",
       "       random_state=0, reg_alpha=0.8, reg_lambda=0.4, scale_pos_weight=1,\n",
       "       seed=None, silent=1, subsample=0.6)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_model.fit(train, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.774950502878\n"
     ]
    }
   ],
   "source": [
    "pb = xgb_model.predict_proba(train)\n",
    "pb = np.array(pb)\n",
    "submit = pd.DataFrame()\n",
    "submit['y1'] = pb.argsort()[np.arange(len(pb)), -1]\n",
    "submit['y2'] = pb.argsort()[np.arange(len(pb)), -2]\n",
    "print(test_score(submit['y1'].values, submit['y2'].values, y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pb = xgb_model.predict_proba(test)\n",
    "pb = np.array(pb)\n",
    "xgb_submit = pd.DataFrame()\n",
    "xgb_submit['y1'] = pb.argsort()[np.arange(len(pb)), -1]\n",
    "xgb_submit['y2'] = pb.argsort()[np.arange(len(pb)), -2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training...\n",
      "[1]\tvalid_0's multi_error: 0.347411\n",
      "Training until validation scores don't improve for 500 rounds.\n",
      "[2]\tvalid_0's multi_error: 0.346367\n",
      "[3]\tvalid_0's multi_error: 0.345833\n",
      "[4]\tvalid_0's multi_error: 0.345744\n",
      "[5]\tvalid_0's multi_error: 0.3455\n",
      "[6]\tvalid_0's multi_error: 0.3455\n",
      "[7]\tvalid_0's multi_error: 0.344677\n",
      "[8]\tvalid_0's multi_error: 0.344077\n",
      "[9]\tvalid_0's multi_error: 0.344033\n",
      "[10]\tvalid_0's multi_error: 0.343455\n",
      "[11]\tvalid_0's multi_error: 0.342921\n",
      "[12]\tvalid_0's multi_error: 0.343032\n",
      "[13]\tvalid_0's multi_error: 0.342543\n",
      "[14]\tvalid_0's multi_error: 0.342721\n",
      "[15]\tvalid_0's multi_error: 0.342721\n",
      "[16]\tvalid_0's multi_error: 0.342232\n",
      "[17]\tvalid_0's multi_error: 0.341965\n",
      "[18]\tvalid_0's multi_error: 0.341099\n",
      "[19]\tvalid_0's multi_error: 0.34121\n",
      "[20]\tvalid_0's multi_error: 0.340432\n",
      "[21]\tvalid_0's multi_error: 0.340676\n",
      "[22]\tvalid_0's multi_error: 0.340476\n",
      "[23]\tvalid_0's multi_error: 0.340432\n",
      "[24]\tvalid_0's multi_error: 0.340254\n",
      "[25]\tvalid_0's multi_error: 0.339498\n",
      "[26]\tvalid_0's multi_error: 0.339387\n",
      "[27]\tvalid_0's multi_error: 0.338609\n",
      "[28]\tvalid_0's multi_error: 0.338164\n",
      "[29]\tvalid_0's multi_error: 0.338098\n",
      "[30]\tvalid_0's multi_error: 0.337875\n",
      "[31]\tvalid_0's multi_error: 0.338075\n",
      "[32]\tvalid_0's multi_error: 0.338075\n",
      "[33]\tvalid_0's multi_error: 0.338231\n",
      "[34]\tvalid_0's multi_error: 0.337675\n",
      "[35]\tvalid_0's multi_error: 0.337031\n",
      "[36]\tvalid_0's multi_error: 0.336897\n",
      "[37]\tvalid_0's multi_error: 0.336342\n",
      "[38]\tvalid_0's multi_error: 0.336075\n",
      "[39]\tvalid_0's multi_error: 0.335941\n",
      "[40]\tvalid_0's multi_error: 0.336075\n",
      "[41]\tvalid_0's multi_error: 0.335786\n",
      "[42]\tvalid_0's multi_error: 0.335986\n",
      "[43]\tvalid_0's multi_error: 0.336164\n",
      "[44]\tvalid_0's multi_error: 0.336097\n",
      "[45]\tvalid_0's multi_error: 0.336075\n",
      "[46]\tvalid_0's multi_error: 0.335964\n",
      "[47]\tvalid_0's multi_error: 0.33623\n",
      "[48]\tvalid_0's multi_error: 0.335964\n",
      "[49]\tvalid_0's multi_error: 0.335586\n",
      "[50]\tvalid_0's multi_error: 0.335608\n",
      "[51]\tvalid_0's multi_error: 0.335808\n",
      "[52]\tvalid_0's multi_error: 0.335808\n",
      "[53]\tvalid_0's multi_error: 0.335786\n",
      "[54]\tvalid_0's multi_error: 0.335919\n",
      "[55]\tvalid_0's multi_error: 0.33543\n",
      "[56]\tvalid_0's multi_error: 0.335675\n",
      "[57]\tvalid_0's multi_error: 0.335808\n",
      "[58]\tvalid_0's multi_error: 0.335653\n",
      "[59]\tvalid_0's multi_error: 0.335564\n",
      "[60]\tvalid_0's multi_error: 0.335297\n",
      "[61]\tvalid_0's multi_error: 0.33503\n",
      "[62]\tvalid_0's multi_error: 0.335008\n",
      "[63]\tvalid_0's multi_error: 0.334741\n",
      "[64]\tvalid_0's multi_error: 0.334941\n",
      "[65]\tvalid_0's multi_error: 0.334897\n",
      "[66]\tvalid_0's multi_error: 0.334875\n",
      "[67]\tvalid_0's multi_error: 0.33463\n",
      "[68]\tvalid_0's multi_error: 0.334452\n",
      "[69]\tvalid_0's multi_error: 0.334185\n",
      "[70]\tvalid_0's multi_error: 0.334274\n",
      "[71]\tvalid_0's multi_error: 0.334341\n",
      "[72]\tvalid_0's multi_error: 0.33383\n",
      "[73]\tvalid_0's multi_error: 0.333719\n",
      "[74]\tvalid_0's multi_error: 0.333896\n",
      "[75]\tvalid_0's multi_error: 0.334052\n",
      "[76]\tvalid_0's multi_error: 0.334141\n",
      "[77]\tvalid_0's multi_error: 0.333941\n",
      "[78]\tvalid_0's multi_error: 0.333852\n",
      "[79]\tvalid_0's multi_error: 0.333963\n",
      "[80]\tvalid_0's multi_error: 0.333763\n",
      "[81]\tvalid_0's multi_error: 0.333585\n",
      "[82]\tvalid_0's multi_error: 0.333541\n",
      "[83]\tvalid_0's multi_error: 0.333519\n",
      "[84]\tvalid_0's multi_error: 0.333496\n",
      "[85]\tvalid_0's multi_error: 0.333741\n",
      "[86]\tvalid_0's multi_error: 0.333541\n",
      "[87]\tvalid_0's multi_error: 0.333541\n",
      "[88]\tvalid_0's multi_error: 0.333674\n",
      "[89]\tvalid_0's multi_error: 0.333674\n",
      "[90]\tvalid_0's multi_error: 0.33363\n",
      "[91]\tvalid_0's multi_error: 0.333874\n",
      "[92]\tvalid_0's multi_error: 0.333563\n",
      "[93]\tvalid_0's multi_error: 0.333474\n",
      "[94]\tvalid_0's multi_error: 0.333741\n",
      "[95]\tvalid_0's multi_error: 0.333652\n",
      "[96]\tvalid_0's multi_error: 0.333563\n",
      "[97]\tvalid_0's multi_error: 0.333341\n",
      "[98]\tvalid_0's multi_error: 0.333163\n",
      "[99]\tvalid_0's multi_error: 0.33303\n",
      "[100]\tvalid_0's multi_error: 0.333074\n",
      "[101]\tvalid_0's multi_error: 0.333118\n",
      "[102]\tvalid_0's multi_error: 0.333118\n",
      "[103]\tvalid_0's multi_error: 0.333118\n",
      "[104]\tvalid_0's multi_error: 0.333141\n",
      "[105]\tvalid_0's multi_error: 0.332941\n",
      "[106]\tvalid_0's multi_error: 0.333207\n",
      "[107]\tvalid_0's multi_error: 0.333007\n",
      "[108]\tvalid_0's multi_error: 0.333007\n",
      "[109]\tvalid_0's multi_error: 0.332785\n",
      "[110]\tvalid_0's multi_error: 0.332785\n",
      "[111]\tvalid_0's multi_error: 0.332829\n",
      "[112]\tvalid_0's multi_error: 0.332807\n",
      "[113]\tvalid_0's multi_error: 0.332652\n",
      "[114]\tvalid_0's multi_error: 0.332563\n",
      "[115]\tvalid_0's multi_error: 0.332518\n",
      "[116]\tvalid_0's multi_error: 0.332585\n",
      "[117]\tvalid_0's multi_error: 0.332607\n",
      "[118]\tvalid_0's multi_error: 0.332518\n",
      "[119]\tvalid_0's multi_error: 0.332385\n",
      "[120]\tvalid_0's multi_error: 0.332407\n",
      "[121]\tvalid_0's multi_error: 0.332607\n",
      "[122]\tvalid_0's multi_error: 0.332674\n",
      "[123]\tvalid_0's multi_error: 0.332696\n",
      "[124]\tvalid_0's multi_error: 0.332696\n",
      "[125]\tvalid_0's multi_error: 0.332607\n",
      "[126]\tvalid_0's multi_error: 0.332563\n",
      "[127]\tvalid_0's multi_error: 0.332207\n",
      "[128]\tvalid_0's multi_error: 0.332274\n",
      "[129]\tvalid_0's multi_error: 0.332007\n",
      "[130]\tvalid_0's multi_error: 0.331896\n",
      "[131]\tvalid_0's multi_error: 0.331629\n",
      "[132]\tvalid_0's multi_error: 0.331785\n",
      "[133]\tvalid_0's multi_error: 0.331785\n",
      "[134]\tvalid_0's multi_error: 0.331696\n",
      "[135]\tvalid_0's multi_error: 0.331651\n",
      "[136]\tvalid_0's multi_error: 0.331807\n",
      "[137]\tvalid_0's multi_error: 0.331562\n",
      "[138]\tvalid_0's multi_error: 0.331518\n",
      "[139]\tvalid_0's multi_error: 0.331629\n",
      "[140]\tvalid_0's multi_error: 0.331518\n",
      "[141]\tvalid_0's multi_error: 0.331429\n",
      "[142]\tvalid_0's multi_error: 0.331718\n",
      "[143]\tvalid_0's multi_error: 0.331518\n",
      "[144]\tvalid_0's multi_error: 0.331385\n",
      "[145]\tvalid_0's multi_error: 0.331429\n",
      "[146]\tvalid_0's multi_error: 0.331318\n",
      "[147]\tvalid_0's multi_error: 0.331251\n",
      "[148]\tvalid_0's multi_error: 0.331251\n",
      "[149]\tvalid_0's multi_error: 0.33134\n",
      "[150]\tvalid_0's multi_error: 0.330962\n",
      "[151]\tvalid_0's multi_error: 0.331118\n",
      "[152]\tvalid_0's multi_error: 0.330829\n",
      "[153]\tvalid_0's multi_error: 0.330651\n",
      "[154]\tvalid_0's multi_error: 0.330696\n",
      "[155]\tvalid_0's multi_error: 0.330562\n",
      "[156]\tvalid_0's multi_error: 0.330651\n",
      "[157]\tvalid_0's multi_error: 0.330673\n",
      "[158]\tvalid_0's multi_error: 0.330651\n",
      "[159]\tvalid_0's multi_error: 0.330762\n",
      "[160]\tvalid_0's multi_error: 0.330918\n",
      "[161]\tvalid_0's multi_error: 0.330607\n",
      "[162]\tvalid_0's multi_error: 0.330518\n",
      "[163]\tvalid_0's multi_error: 0.330251\n",
      "[164]\tvalid_0's multi_error: 0.330162\n",
      "[165]\tvalid_0's multi_error: 0.330273\n",
      "[166]\tvalid_0's multi_error: 0.330051\n",
      "[167]\tvalid_0's multi_error: 0.330051\n",
      "[168]\tvalid_0's multi_error: 0.330051\n",
      "[169]\tvalid_0's multi_error: 0.330207\n",
      "[170]\tvalid_0's multi_error: 0.330118\n",
      "[171]\tvalid_0's multi_error: 0.330429\n",
      "[172]\tvalid_0's multi_error: 0.330362\n",
      "[173]\tvalid_0's multi_error: 0.330384\n",
      "[174]\tvalid_0's multi_error: 0.330429\n",
      "[175]\tvalid_0's multi_error: 0.33034\n",
      "[176]\tvalid_0's multi_error: 0.330229\n",
      "[177]\tvalid_0's multi_error: 0.330051\n",
      "[178]\tvalid_0's multi_error: 0.329806\n",
      "[179]\tvalid_0's multi_error: 0.329695\n",
      "[180]\tvalid_0's multi_error: 0.329584\n",
      "[181]\tvalid_0's multi_error: 0.329584\n",
      "[182]\tvalid_0's multi_error: 0.329562\n",
      "[183]\tvalid_0's multi_error: 0.329584\n",
      "[184]\tvalid_0's multi_error: 0.329651\n",
      "[185]\tvalid_0's multi_error: 0.329717\n",
      "[186]\tvalid_0's multi_error: 0.329451\n",
      "[187]\tvalid_0's multi_error: 0.329451\n",
      "[188]\tvalid_0's multi_error: 0.329429\n",
      "[189]\tvalid_0's multi_error: 0.329251\n",
      "[190]\tvalid_0's multi_error: 0.329273\n",
      "[191]\tvalid_0's multi_error: 0.329362\n",
      "[192]\tvalid_0's multi_error: 0.329384\n",
      "[193]\tvalid_0's multi_error: 0.329228\n",
      "[194]\tvalid_0's multi_error: 0.329228\n",
      "[195]\tvalid_0's multi_error: 0.329162\n",
      "[196]\tvalid_0's multi_error: 0.328917\n",
      "[197]\tvalid_0's multi_error: 0.328984\n",
      "[198]\tvalid_0's multi_error: 0.328984\n",
      "[199]\tvalid_0's multi_error: 0.32914\n",
      "[200]\tvalid_0's multi_error: 0.329206\n",
      "[201]\tvalid_0's multi_error: 0.328939\n",
      "[202]\tvalid_0's multi_error: 0.328917\n",
      "[203]\tvalid_0's multi_error: 0.328828\n",
      "[204]\tvalid_0's multi_error: 0.328873\n",
      "[205]\tvalid_0's multi_error: 0.328873\n",
      "[206]\tvalid_0's multi_error: 0.328784\n",
      "[207]\tvalid_0's multi_error: 0.328739\n",
      "[208]\tvalid_0's multi_error: 0.328851\n",
      "[209]\tvalid_0's multi_error: 0.328739\n",
      "[210]\tvalid_0's multi_error: 0.328762\n",
      "[211]\tvalid_0's multi_error: 0.328695\n",
      "[212]\tvalid_0's multi_error: 0.328606\n",
      "[213]\tvalid_0's multi_error: 0.328406\n",
      "[214]\tvalid_0's multi_error: 0.328739\n",
      "[215]\tvalid_0's multi_error: 0.328673\n",
      "[216]\tvalid_0's multi_error: 0.328562\n",
      "[217]\tvalid_0's multi_error: 0.328851\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[218]\tvalid_0's multi_error: 0.328873\n",
      "[219]\tvalid_0's multi_error: 0.328806\n",
      "[220]\tvalid_0's multi_error: 0.328895\n",
      "[221]\tvalid_0's multi_error: 0.328851\n",
      "[222]\tvalid_0's multi_error: 0.328873\n",
      "[223]\tvalid_0's multi_error: 0.328806\n",
      "[224]\tvalid_0's multi_error: 0.328984\n",
      "[225]\tvalid_0's multi_error: 0.328939\n",
      "[226]\tvalid_0's multi_error: 0.328917\n",
      "[227]\tvalid_0's multi_error: 0.328717\n",
      "[228]\tvalid_0's multi_error: 0.328828\n",
      "[229]\tvalid_0's multi_error: 0.328917\n",
      "[230]\tvalid_0's multi_error: 0.328895\n",
      "[231]\tvalid_0's multi_error: 0.328717\n",
      "[232]\tvalid_0's multi_error: 0.329095\n",
      "[233]\tvalid_0's multi_error: 0.328895\n",
      "[234]\tvalid_0's multi_error: 0.328873\n",
      "[235]\tvalid_0's multi_error: 0.328739\n",
      "[236]\tvalid_0's multi_error: 0.328717\n",
      "[237]\tvalid_0's multi_error: 0.328873\n",
      "[238]\tvalid_0's multi_error: 0.328895\n",
      "[239]\tvalid_0's multi_error: 0.328784\n",
      "[240]\tvalid_0's multi_error: 0.328762\n",
      "[241]\tvalid_0's multi_error: 0.328917\n",
      "[242]\tvalid_0's multi_error: 0.329073\n",
      "[243]\tvalid_0's multi_error: 0.328939\n",
      "[244]\tvalid_0's multi_error: 0.328851\n",
      "[245]\tvalid_0's multi_error: 0.328851\n",
      "[246]\tvalid_0's multi_error: 0.329051\n",
      "[247]\tvalid_0's multi_error: 0.32914\n",
      "[248]\tvalid_0's multi_error: 0.329162\n",
      "[249]\tvalid_0's multi_error: 0.329273\n",
      "[250]\tvalid_0's multi_error: 0.329228\n",
      "[251]\tvalid_0's multi_error: 0.329184\n",
      "[252]\tvalid_0's multi_error: 0.329073\n",
      "[253]\tvalid_0's multi_error: 0.329228\n",
      "[254]\tvalid_0's multi_error: 0.329406\n",
      "[255]\tvalid_0's multi_error: 0.329206\n",
      "[256]\tvalid_0's multi_error: 0.329228\n",
      "[257]\tvalid_0's multi_error: 0.329162\n",
      "[258]\tvalid_0's multi_error: 0.329073\n",
      "[259]\tvalid_0's multi_error: 0.329028\n",
      "[260]\tvalid_0's multi_error: 0.328762\n",
      "[261]\tvalid_0's multi_error: 0.328673\n",
      "[262]\tvalid_0's multi_error: 0.328717\n",
      "[263]\tvalid_0's multi_error: 0.32865\n",
      "[264]\tvalid_0's multi_error: 0.328762\n",
      "[265]\tvalid_0's multi_error: 0.328828\n",
      "[266]\tvalid_0's multi_error: 0.328828\n",
      "[267]\tvalid_0's multi_error: 0.328873\n",
      "[268]\tvalid_0's multi_error: 0.328873\n",
      "[269]\tvalid_0's multi_error: 0.328762\n",
      "[270]\tvalid_0's multi_error: 0.328695\n",
      "[271]\tvalid_0's multi_error: 0.328851\n",
      "[272]\tvalid_0's multi_error: 0.328739\n",
      "[273]\tvalid_0's multi_error: 0.328873\n",
      "[274]\tvalid_0's multi_error: 0.328851\n",
      "[275]\tvalid_0's multi_error: 0.328895\n",
      "[276]\tvalid_0's multi_error: 0.328917\n",
      "[277]\tvalid_0's multi_error: 0.328984\n",
      "[278]\tvalid_0's multi_error: 0.329206\n",
      "[279]\tvalid_0's multi_error: 0.329006\n",
      "[280]\tvalid_0's multi_error: 0.328984\n",
      "[281]\tvalid_0's multi_error: 0.328784\n",
      "[282]\tvalid_0's multi_error: 0.328917\n",
      "[283]\tvalid_0's multi_error: 0.328762\n",
      "[284]\tvalid_0's multi_error: 0.328762\n",
      "[285]\tvalid_0's multi_error: 0.32865\n",
      "[286]\tvalid_0's multi_error: 0.328562\n",
      "[287]\tvalid_0's multi_error: 0.328406\n",
      "[288]\tvalid_0's multi_error: 0.328428\n",
      "[289]\tvalid_0's multi_error: 0.328495\n",
      "[290]\tvalid_0's multi_error: 0.32845\n",
      "[291]\tvalid_0's multi_error: 0.328495\n",
      "[292]\tvalid_0's multi_error: 0.328517\n",
      "[293]\tvalid_0's multi_error: 0.328406\n",
      "[294]\tvalid_0's multi_error: 0.328406\n",
      "[295]\tvalid_0's multi_error: 0.32845\n",
      "[296]\tvalid_0's multi_error: 0.328339\n",
      "[297]\tvalid_0's multi_error: 0.327939\n",
      "[298]\tvalid_0's multi_error: 0.328117\n",
      "[299]\tvalid_0's multi_error: 0.328295\n",
      "[300]\tvalid_0's multi_error: 0.328273\n",
      "[301]\tvalid_0's multi_error: 0.32845\n",
      "[302]\tvalid_0's multi_error: 0.328517\n",
      "[303]\tvalid_0's multi_error: 0.328562\n",
      "[304]\tvalid_0's multi_error: 0.328584\n",
      "[305]\tvalid_0's multi_error: 0.328606\n",
      "[306]\tvalid_0's multi_error: 0.328473\n",
      "[307]\tvalid_0's multi_error: 0.328739\n",
      "[308]\tvalid_0's multi_error: 0.328606\n",
      "[309]\tvalid_0's multi_error: 0.32865\n",
      "[310]\tvalid_0's multi_error: 0.328628\n",
      "[311]\tvalid_0's multi_error: 0.328562\n",
      "[312]\tvalid_0's multi_error: 0.328428\n",
      "[313]\tvalid_0's multi_error: 0.328362\n",
      "[314]\tvalid_0's multi_error: 0.328273\n",
      "[315]\tvalid_0's multi_error: 0.328161\n",
      "[316]\tvalid_0's multi_error: 0.32825\n",
      "[317]\tvalid_0's multi_error: 0.328073\n",
      "[318]\tvalid_0's multi_error: 0.328095\n",
      "[319]\tvalid_0's multi_error: 0.327961\n",
      "[320]\tvalid_0's multi_error: 0.327961\n",
      "[321]\tvalid_0's multi_error: 0.328073\n",
      "[322]\tvalid_0's multi_error: 0.328117\n",
      "[323]\tvalid_0's multi_error: 0.328161\n",
      "[324]\tvalid_0's multi_error: 0.327984\n",
      "[325]\tvalid_0's multi_error: 0.328073\n",
      "[326]\tvalid_0's multi_error: 0.328184\n",
      "[327]\tvalid_0's multi_error: 0.328139\n",
      "[328]\tvalid_0's multi_error: 0.327984\n",
      "[329]\tvalid_0's multi_error: 0.328139\n",
      "[330]\tvalid_0's multi_error: 0.328139\n",
      "[331]\tvalid_0's multi_error: 0.328273\n",
      "[332]\tvalid_0's multi_error: 0.328228\n",
      "[333]\tvalid_0's multi_error: 0.328161\n",
      "[334]\tvalid_0's multi_error: 0.328273\n",
      "[335]\tvalid_0's multi_error: 0.328295\n",
      "[336]\tvalid_0's multi_error: 0.328073\n",
      "[337]\tvalid_0's multi_error: 0.328362\n",
      "[338]\tvalid_0's multi_error: 0.328117\n",
      "[339]\tvalid_0's multi_error: 0.328273\n",
      "[340]\tvalid_0's multi_error: 0.328317\n",
      "[341]\tvalid_0's multi_error: 0.328362\n",
      "[342]\tvalid_0's multi_error: 0.328339\n",
      "[343]\tvalid_0's multi_error: 0.328406\n",
      "[344]\tvalid_0's multi_error: 0.328317\n",
      "[345]\tvalid_0's multi_error: 0.328139\n",
      "[346]\tvalid_0's multi_error: 0.328139\n",
      "[347]\tvalid_0's multi_error: 0.328095\n",
      "[348]\tvalid_0's multi_error: 0.328117\n",
      "[349]\tvalid_0's multi_error: 0.328228\n",
      "[350]\tvalid_0's multi_error: 0.32825\n",
      "[351]\tvalid_0's multi_error: 0.328184\n",
      "[352]\tvalid_0's multi_error: 0.328028\n",
      "[353]\tvalid_0's multi_error: 0.32805\n",
      "[354]\tvalid_0's multi_error: 0.327917\n",
      "[355]\tvalid_0's multi_error: 0.32785\n",
      "[356]\tvalid_0's multi_error: 0.327761\n",
      "[357]\tvalid_0's multi_error: 0.327628\n",
      "[358]\tvalid_0's multi_error: 0.327561\n",
      "[359]\tvalid_0's multi_error: 0.327517\n",
      "[360]\tvalid_0's multi_error: 0.327428\n",
      "[361]\tvalid_0's multi_error: 0.327383\n",
      "[362]\tvalid_0's multi_error: 0.32745\n",
      "[363]\tvalid_0's multi_error: 0.327383\n",
      "[364]\tvalid_0's multi_error: 0.327428\n",
      "[365]\tvalid_0's multi_error: 0.327517\n",
      "[366]\tvalid_0's multi_error: 0.327339\n",
      "[367]\tvalid_0's multi_error: 0.327406\n",
      "[368]\tvalid_0's multi_error: 0.327428\n",
      "[369]\tvalid_0's multi_error: 0.327428\n",
      "[370]\tvalid_0's multi_error: 0.327428\n",
      "[371]\tvalid_0's multi_error: 0.327472\n",
      "[372]\tvalid_0's multi_error: 0.32765\n",
      "[373]\tvalid_0's multi_error: 0.32765\n",
      "[374]\tvalid_0's multi_error: 0.327672\n",
      "[375]\tvalid_0's multi_error: 0.327784\n",
      "[376]\tvalid_0's multi_error: 0.327784\n",
      "[377]\tvalid_0's multi_error: 0.327739\n",
      "[378]\tvalid_0's multi_error: 0.327939\n",
      "[379]\tvalid_0's multi_error: 0.328117\n",
      "[380]\tvalid_0's multi_error: 0.328117\n",
      "[381]\tvalid_0's multi_error: 0.327895\n",
      "[382]\tvalid_0's multi_error: 0.327872\n",
      "[383]\tvalid_0's multi_error: 0.327917\n",
      "[384]\tvalid_0's multi_error: 0.327828\n",
      "[385]\tvalid_0's multi_error: 0.327872\n",
      "[386]\tvalid_0's multi_error: 0.327828\n",
      "[387]\tvalid_0's multi_error: 0.327606\n",
      "[388]\tvalid_0's multi_error: 0.327606\n",
      "[389]\tvalid_0's multi_error: 0.327739\n",
      "[390]\tvalid_0's multi_error: 0.327739\n",
      "[391]\tvalid_0's multi_error: 0.327606\n",
      "[392]\tvalid_0's multi_error: 0.327628\n",
      "[393]\tvalid_0's multi_error: 0.327584\n",
      "[394]\tvalid_0's multi_error: 0.327584\n",
      "[395]\tvalid_0's multi_error: 0.327695\n",
      "[396]\tvalid_0's multi_error: 0.327406\n",
      "[397]\tvalid_0's multi_error: 0.327428\n",
      "[398]\tvalid_0's multi_error: 0.327628\n",
      "[399]\tvalid_0's multi_error: 0.32725\n",
      "[400]\tvalid_0's multi_error: 0.327428\n",
      "[401]\tvalid_0's multi_error: 0.327428\n",
      "[402]\tvalid_0's multi_error: 0.327383\n",
      "[403]\tvalid_0's multi_error: 0.327472\n",
      "[404]\tvalid_0's multi_error: 0.327472\n",
      "[405]\tvalid_0's multi_error: 0.327539\n",
      "[406]\tvalid_0's multi_error: 0.327584\n",
      "[407]\tvalid_0's multi_error: 0.327584\n",
      "[408]\tvalid_0's multi_error: 0.327628\n",
      "[409]\tvalid_0's multi_error: 0.327717\n",
      "[410]\tvalid_0's multi_error: 0.327761\n",
      "[411]\tvalid_0's multi_error: 0.327695\n",
      "[412]\tvalid_0's multi_error: 0.327695\n",
      "[413]\tvalid_0's multi_error: 0.327784\n",
      "[414]\tvalid_0's multi_error: 0.32785\n",
      "[415]\tvalid_0's multi_error: 0.327872\n",
      "[416]\tvalid_0's multi_error: 0.327872\n",
      "[417]\tvalid_0's multi_error: 0.328006\n",
      "[418]\tvalid_0's multi_error: 0.327761\n",
      "[419]\tvalid_0's multi_error: 0.327806\n",
      "[420]\tvalid_0's multi_error: 0.327672\n",
      "[421]\tvalid_0's multi_error: 0.327428\n",
      "[422]\tvalid_0's multi_error: 0.327139\n",
      "[423]\tvalid_0's multi_error: 0.327206\n",
      "[424]\tvalid_0's multi_error: 0.327094\n",
      "[425]\tvalid_0's multi_error: 0.327072\n",
      "[426]\tvalid_0's multi_error: 0.327139\n",
      "[427]\tvalid_0's multi_error: 0.327183\n",
      "[428]\tvalid_0's multi_error: 0.327228\n",
      "[429]\tvalid_0's multi_error: 0.32725\n",
      "[430]\tvalid_0's multi_error: 0.327183\n",
      "[431]\tvalid_0's multi_error: 0.327317\n",
      "[432]\tvalid_0's multi_error: 0.327295\n",
      "[433]\tvalid_0's multi_error: 0.327206\n",
      "[434]\tvalid_0's multi_error: 0.327094\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[435]\tvalid_0's multi_error: 0.326983\n",
      "[436]\tvalid_0's multi_error: 0.327117\n",
      "[437]\tvalid_0's multi_error: 0.32705\n",
      "[438]\tvalid_0's multi_error: 0.327028\n",
      "[439]\tvalid_0's multi_error: 0.327206\n",
      "[440]\tvalid_0's multi_error: 0.327117\n",
      "[441]\tvalid_0's multi_error: 0.326983\n",
      "[442]\tvalid_0's multi_error: 0.327139\n",
      "[443]\tvalid_0's multi_error: 0.327317\n",
      "[444]\tvalid_0's multi_error: 0.32725\n",
      "[445]\tvalid_0's multi_error: 0.327295\n",
      "[446]\tvalid_0's multi_error: 0.327117\n",
      "[447]\tvalid_0's multi_error: 0.327206\n",
      "[448]\tvalid_0's multi_error: 0.327295\n",
      "[449]\tvalid_0's multi_error: 0.327317\n",
      "[450]\tvalid_0's multi_error: 0.327339\n",
      "[451]\tvalid_0's multi_error: 0.327317\n",
      "[452]\tvalid_0's multi_error: 0.327428\n",
      "[453]\tvalid_0's multi_error: 0.32745\n",
      "[454]\tvalid_0's multi_error: 0.327295\n",
      "[455]\tvalid_0's multi_error: 0.327339\n",
      "[456]\tvalid_0's multi_error: 0.327272\n",
      "[457]\tvalid_0's multi_error: 0.327406\n",
      "[458]\tvalid_0's multi_error: 0.327317\n",
      "[459]\tvalid_0's multi_error: 0.327183\n",
      "[460]\tvalid_0's multi_error: 0.32705\n",
      "[461]\tvalid_0's multi_error: 0.327028\n",
      "[462]\tvalid_0's multi_error: 0.327139\n",
      "[463]\tvalid_0's multi_error: 0.327361\n",
      "[464]\tvalid_0's multi_error: 0.327428\n",
      "[465]\tvalid_0's multi_error: 0.327339\n",
      "[466]\tvalid_0's multi_error: 0.327161\n",
      "[467]\tvalid_0's multi_error: 0.327161\n",
      "[468]\tvalid_0's multi_error: 0.32725\n",
      "[469]\tvalid_0's multi_error: 0.327117\n",
      "[470]\tvalid_0's multi_error: 0.327028\n",
      "[471]\tvalid_0's multi_error: 0.326939\n",
      "[472]\tvalid_0's multi_error: 0.32725\n",
      "[473]\tvalid_0's multi_error: 0.327406\n",
      "[474]\tvalid_0's multi_error: 0.327361\n",
      "[475]\tvalid_0's multi_error: 0.327517\n",
      "[476]\tvalid_0's multi_error: 0.327406\n",
      "[477]\tvalid_0's multi_error: 0.327472\n",
      "[478]\tvalid_0's multi_error: 0.327628\n",
      "[479]\tvalid_0's multi_error: 0.327628\n",
      "[480]\tvalid_0's multi_error: 0.327784\n",
      "[481]\tvalid_0's multi_error: 0.327717\n",
      "[482]\tvalid_0's multi_error: 0.327761\n",
      "[483]\tvalid_0's multi_error: 0.327695\n",
      "[484]\tvalid_0's multi_error: 0.327495\n",
      "[485]\tvalid_0's multi_error: 0.327539\n",
      "[486]\tvalid_0's multi_error: 0.327428\n",
      "[487]\tvalid_0's multi_error: 0.327406\n",
      "[488]\tvalid_0's multi_error: 0.327495\n",
      "[489]\tvalid_0's multi_error: 0.327428\n",
      "[490]\tvalid_0's multi_error: 0.32745\n",
      "[491]\tvalid_0's multi_error: 0.327383\n",
      "[492]\tvalid_0's multi_error: 0.327272\n",
      "[493]\tvalid_0's multi_error: 0.327272\n",
      "[494]\tvalid_0's multi_error: 0.327161\n",
      "[495]\tvalid_0's multi_error: 0.327339\n",
      "[496]\tvalid_0's multi_error: 0.327183\n",
      "[497]\tvalid_0's multi_error: 0.327183\n",
      "[498]\tvalid_0's multi_error: 0.327183\n",
      "[499]\tvalid_0's multi_error: 0.327428\n",
      "[500]\tvalid_0's multi_error: 0.327206\n",
      "[501]\tvalid_0's multi_error: 0.327183\n",
      "[502]\tvalid_0's multi_error: 0.327272\n",
      "[503]\tvalid_0's multi_error: 0.327295\n",
      "[504]\tvalid_0's multi_error: 0.327139\n",
      "[505]\tvalid_0's multi_error: 0.327117\n",
      "[506]\tvalid_0's multi_error: 0.327028\n",
      "[507]\tvalid_0's multi_error: 0.326694\n",
      "[508]\tvalid_0's multi_error: 0.326739\n",
      "[509]\tvalid_0's multi_error: 0.326761\n",
      "[510]\tvalid_0's multi_error: 0.32665\n",
      "[511]\tvalid_0's multi_error: 0.32665\n",
      "[512]\tvalid_0's multi_error: 0.326694\n",
      "[513]\tvalid_0's multi_error: 0.326694\n",
      "[514]\tvalid_0's multi_error: 0.326783\n",
      "[515]\tvalid_0's multi_error: 0.326694\n",
      "[516]\tvalid_0's multi_error: 0.32685\n",
      "[517]\tvalid_0's multi_error: 0.326983\n",
      "[518]\tvalid_0's multi_error: 0.326983\n",
      "[519]\tvalid_0's multi_error: 0.326961\n",
      "[520]\tvalid_0's multi_error: 0.326939\n",
      "[521]\tvalid_0's multi_error: 0.327228\n",
      "[522]\tvalid_0's multi_error: 0.327183\n",
      "[523]\tvalid_0's multi_error: 0.327028\n",
      "[524]\tvalid_0's multi_error: 0.32705\n",
      "[525]\tvalid_0's multi_error: 0.327183\n",
      "[526]\tvalid_0's multi_error: 0.327228\n",
      "[527]\tvalid_0's multi_error: 0.327139\n",
      "[528]\tvalid_0's multi_error: 0.327206\n",
      "[529]\tvalid_0's multi_error: 0.327472\n",
      "[530]\tvalid_0's multi_error: 0.327584\n",
      "[531]\tvalid_0's multi_error: 0.327495\n",
      "[532]\tvalid_0's multi_error: 0.327495\n",
      "[533]\tvalid_0's multi_error: 0.327428\n",
      "[534]\tvalid_0's multi_error: 0.327495\n",
      "[535]\tvalid_0's multi_error: 0.32745\n",
      "[536]\tvalid_0's multi_error: 0.327383\n",
      "[537]\tvalid_0's multi_error: 0.327428\n",
      "[538]\tvalid_0's multi_error: 0.327406\n",
      "[539]\tvalid_0's multi_error: 0.327317\n",
      "[540]\tvalid_0's multi_error: 0.327272\n",
      "[541]\tvalid_0's multi_error: 0.327161\n",
      "[542]\tvalid_0's multi_error: 0.327206\n",
      "[543]\tvalid_0's multi_error: 0.327139\n",
      "[544]\tvalid_0's multi_error: 0.327228\n",
      "[545]\tvalid_0's multi_error: 0.327117\n",
      "[546]\tvalid_0's multi_error: 0.326983\n",
      "[547]\tvalid_0's multi_error: 0.327028\n",
      "[548]\tvalid_0's multi_error: 0.327006\n",
      "[549]\tvalid_0's multi_error: 0.326872\n",
      "[550]\tvalid_0's multi_error: 0.326894\n",
      "[551]\tvalid_0's multi_error: 0.326894\n",
      "[552]\tvalid_0's multi_error: 0.327006\n",
      "[553]\tvalid_0's multi_error: 0.326872\n",
      "[554]\tvalid_0's multi_error: 0.326806\n",
      "[555]\tvalid_0's multi_error: 0.32685\n",
      "[556]\tvalid_0's multi_error: 0.326806\n",
      "[557]\tvalid_0's multi_error: 0.32685\n",
      "[558]\tvalid_0's multi_error: 0.326761\n",
      "[559]\tvalid_0's multi_error: 0.326717\n",
      "[560]\tvalid_0's multi_error: 0.32665\n",
      "[561]\tvalid_0's multi_error: 0.326717\n",
      "[562]\tvalid_0's multi_error: 0.326806\n",
      "[563]\tvalid_0's multi_error: 0.326672\n",
      "[564]\tvalid_0's multi_error: 0.326672\n",
      "[565]\tvalid_0's multi_error: 0.326717\n",
      "[566]\tvalid_0's multi_error: 0.326605\n",
      "[567]\tvalid_0's multi_error: 0.326672\n",
      "[568]\tvalid_0's multi_error: 0.326717\n",
      "[569]\tvalid_0's multi_error: 0.326672\n",
      "[570]\tvalid_0's multi_error: 0.326717\n",
      "[571]\tvalid_0's multi_error: 0.32665\n",
      "[572]\tvalid_0's multi_error: 0.326517\n",
      "[573]\tvalid_0's multi_error: 0.326383\n",
      "[574]\tvalid_0's multi_error: 0.326539\n",
      "[575]\tvalid_0's multi_error: 0.326539\n",
      "[576]\tvalid_0's multi_error: 0.326494\n",
      "[577]\tvalid_0's multi_error: 0.326605\n",
      "[578]\tvalid_0's multi_error: 0.326761\n",
      "[579]\tvalid_0's multi_error: 0.326672\n",
      "[580]\tvalid_0's multi_error: 0.32665\n",
      "[581]\tvalid_0's multi_error: 0.326717\n",
      "[582]\tvalid_0's multi_error: 0.326806\n",
      "[583]\tvalid_0's multi_error: 0.326783\n",
      "[584]\tvalid_0's multi_error: 0.326761\n",
      "[585]\tvalid_0's multi_error: 0.326961\n",
      "[586]\tvalid_0's multi_error: 0.326761\n",
      "[587]\tvalid_0's multi_error: 0.326739\n",
      "[588]\tvalid_0's multi_error: 0.326717\n",
      "[589]\tvalid_0's multi_error: 0.32685\n",
      "[590]\tvalid_0's multi_error: 0.326939\n",
      "[591]\tvalid_0's multi_error: 0.32685\n",
      "[592]\tvalid_0's multi_error: 0.326694\n",
      "[593]\tvalid_0's multi_error: 0.326717\n",
      "[594]\tvalid_0's multi_error: 0.326694\n",
      "[595]\tvalid_0's multi_error: 0.326672\n",
      "[596]\tvalid_0's multi_error: 0.326783\n",
      "[597]\tvalid_0's multi_error: 0.326605\n",
      "[598]\tvalid_0's multi_error: 0.326628\n",
      "[599]\tvalid_0's multi_error: 0.326828\n",
      "[600]\tvalid_0's multi_error: 0.326628\n",
      "[601]\tvalid_0's multi_error: 0.32665\n",
      "[602]\tvalid_0's multi_error: 0.326739\n",
      "[603]\tvalid_0's multi_error: 0.326694\n",
      "[604]\tvalid_0's multi_error: 0.32665\n",
      "[605]\tvalid_0's multi_error: 0.326628\n",
      "[606]\tvalid_0's multi_error: 0.32665\n",
      "[607]\tvalid_0's multi_error: 0.326605\n",
      "[608]\tvalid_0's multi_error: 0.326628\n",
      "[609]\tvalid_0's multi_error: 0.326517\n",
      "[610]\tvalid_0's multi_error: 0.326361\n",
      "[611]\tvalid_0's multi_error: 0.326583\n",
      "[612]\tvalid_0's multi_error: 0.326383\n",
      "[613]\tvalid_0's multi_error: 0.326428\n",
      "[614]\tvalid_0's multi_error: 0.326272\n",
      "[615]\tvalid_0's multi_error: 0.326339\n",
      "[616]\tvalid_0's multi_error: 0.326205\n",
      "[617]\tvalid_0's multi_error: 0.326272\n",
      "[618]\tvalid_0's multi_error: 0.326139\n",
      "[619]\tvalid_0's multi_error: 0.326294\n",
      "[620]\tvalid_0's multi_error: 0.326228\n",
      "[621]\tvalid_0's multi_error: 0.326094\n",
      "[622]\tvalid_0's multi_error: 0.326139\n",
      "[623]\tvalid_0's multi_error: 0.326161\n",
      "[624]\tvalid_0's multi_error: 0.32625\n",
      "[625]\tvalid_0's multi_error: 0.326316\n",
      "[626]\tvalid_0's multi_error: 0.326405\n",
      "[627]\tvalid_0's multi_error: 0.326161\n",
      "[628]\tvalid_0's multi_error: 0.326161\n",
      "[629]\tvalid_0's multi_error: 0.326028\n",
      "[630]\tvalid_0's multi_error: 0.32605\n",
      "[631]\tvalid_0's multi_error: 0.326228\n",
      "[632]\tvalid_0's multi_error: 0.32625\n",
      "[633]\tvalid_0's multi_error: 0.326272\n",
      "[634]\tvalid_0's multi_error: 0.326383\n",
      "[635]\tvalid_0's multi_error: 0.32645\n",
      "[636]\tvalid_0's multi_error: 0.326316\n",
      "[637]\tvalid_0's multi_error: 0.326539\n",
      "[638]\tvalid_0's multi_error: 0.326539\n",
      "[639]\tvalid_0's multi_error: 0.326672\n",
      "[640]\tvalid_0's multi_error: 0.326561\n",
      "[641]\tvalid_0's multi_error: 0.326494\n",
      "[642]\tvalid_0's multi_error: 0.326472\n",
      "[643]\tvalid_0's multi_error: 0.326272\n",
      "[644]\tvalid_0's multi_error: 0.326294\n",
      "[645]\tvalid_0's multi_error: 0.326361\n",
      "[646]\tvalid_0's multi_error: 0.32645\n",
      "[647]\tvalid_0's multi_error: 0.326605\n",
      "[648]\tvalid_0's multi_error: 0.326517\n",
      "[649]\tvalid_0's multi_error: 0.326583\n",
      "[650]\tvalid_0's multi_error: 0.32665\n",
      "[651]\tvalid_0's multi_error: 0.32665\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[652]\tvalid_0's multi_error: 0.326717\n",
      "[653]\tvalid_0's multi_error: 0.326806\n",
      "[654]\tvalid_0's multi_error: 0.326761\n",
      "[655]\tvalid_0's multi_error: 0.326761\n",
      "[656]\tvalid_0's multi_error: 0.326561\n",
      "[657]\tvalid_0's multi_error: 0.326672\n",
      "[658]\tvalid_0's multi_error: 0.32665\n",
      "[659]\tvalid_0's multi_error: 0.326694\n",
      "[660]\tvalid_0's multi_error: 0.326806\n",
      "[661]\tvalid_0's multi_error: 0.326717\n",
      "[662]\tvalid_0's multi_error: 0.326539\n",
      "[663]\tvalid_0's multi_error: 0.326561\n",
      "[664]\tvalid_0's multi_error: 0.326672\n",
      "[665]\tvalid_0's multi_error: 0.32665\n",
      "[666]\tvalid_0's multi_error: 0.326628\n",
      "[667]\tvalid_0's multi_error: 0.326494\n",
      "[668]\tvalid_0's multi_error: 0.326517\n",
      "[669]\tvalid_0's multi_error: 0.326717\n",
      "[670]\tvalid_0's multi_error: 0.326694\n",
      "[671]\tvalid_0's multi_error: 0.326672\n",
      "[672]\tvalid_0's multi_error: 0.326761\n",
      "[673]\tvalid_0's multi_error: 0.326983\n",
      "[674]\tvalid_0's multi_error: 0.327072\n",
      "[675]\tvalid_0's multi_error: 0.327183\n",
      "[676]\tvalid_0's multi_error: 0.327117\n",
      "[677]\tvalid_0's multi_error: 0.327161\n",
      "[678]\tvalid_0's multi_error: 0.326983\n",
      "[679]\tvalid_0's multi_error: 0.326917\n",
      "[680]\tvalid_0's multi_error: 0.32705\n",
      "[681]\tvalid_0's multi_error: 0.327139\n",
      "[682]\tvalid_0's multi_error: 0.327094\n",
      "[683]\tvalid_0's multi_error: 0.32705\n",
      "[684]\tvalid_0's multi_error: 0.326872\n",
      "[685]\tvalid_0's multi_error: 0.326939\n",
      "[686]\tvalid_0's multi_error: 0.326939\n",
      "[687]\tvalid_0's multi_error: 0.326872\n",
      "[688]\tvalid_0's multi_error: 0.326939\n",
      "[689]\tvalid_0's multi_error: 0.32685\n",
      "[690]\tvalid_0's multi_error: 0.326939\n",
      "[691]\tvalid_0's multi_error: 0.326894\n",
      "[692]\tvalid_0's multi_error: 0.326761\n",
      "[693]\tvalid_0's multi_error: 0.326628\n",
      "[694]\tvalid_0's multi_error: 0.326694\n",
      "[695]\tvalid_0's multi_error: 0.326628\n",
      "[696]\tvalid_0's multi_error: 0.326672\n",
      "[697]\tvalid_0's multi_error: 0.326694\n",
      "[698]\tvalid_0's multi_error: 0.326517\n",
      "[699]\tvalid_0's multi_error: 0.326517\n",
      "[700]\tvalid_0's multi_error: 0.326561\n",
      "[701]\tvalid_0's multi_error: 0.326628\n",
      "[702]\tvalid_0's multi_error: 0.326717\n",
      "[703]\tvalid_0's multi_error: 0.326583\n",
      "[704]\tvalid_0's multi_error: 0.326628\n",
      "[705]\tvalid_0's multi_error: 0.326316\n",
      "[706]\tvalid_0's multi_error: 0.326339\n",
      "[707]\tvalid_0's multi_error: 0.326361\n",
      "[708]\tvalid_0's multi_error: 0.326339\n",
      "[709]\tvalid_0's multi_error: 0.326383\n",
      "[710]\tvalid_0's multi_error: 0.326294\n",
      "[711]\tvalid_0's multi_error: 0.326494\n",
      "[712]\tvalid_0's multi_error: 0.326316\n",
      "[713]\tvalid_0's multi_error: 0.326272\n",
      "[714]\tvalid_0's multi_error: 0.326205\n",
      "[715]\tvalid_0's multi_error: 0.326161\n",
      "[716]\tvalid_0's multi_error: 0.326072\n",
      "[717]\tvalid_0's multi_error: 0.326094\n",
      "[718]\tvalid_0's multi_error: 0.326183\n",
      "[719]\tvalid_0's multi_error: 0.326205\n",
      "[720]\tvalid_0's multi_error: 0.326005\n",
      "[721]\tvalid_0's multi_error: 0.326028\n",
      "[722]\tvalid_0's multi_error: 0.326072\n",
      "[723]\tvalid_0's multi_error: 0.32605\n",
      "[724]\tvalid_0's multi_error: 0.326094\n",
      "[725]\tvalid_0's multi_error: 0.325983\n",
      "[726]\tvalid_0's multi_error: 0.326005\n",
      "[727]\tvalid_0's multi_error: 0.326028\n",
      "[728]\tvalid_0's multi_error: 0.326094\n",
      "[729]\tvalid_0's multi_error: 0.326183\n",
      "[730]\tvalid_0's multi_error: 0.326294\n",
      "[731]\tvalid_0's multi_error: 0.326339\n",
      "[732]\tvalid_0's multi_error: 0.326094\n",
      "[733]\tvalid_0's multi_error: 0.326161\n",
      "[734]\tvalid_0's multi_error: 0.326205\n",
      "[735]\tvalid_0's multi_error: 0.32625\n",
      "[736]\tvalid_0's multi_error: 0.32605\n",
      "[737]\tvalid_0's multi_error: 0.326072\n",
      "[738]\tvalid_0's multi_error: 0.325961\n",
      "[739]\tvalid_0's multi_error: 0.326005\n",
      "[740]\tvalid_0's multi_error: 0.325939\n",
      "[741]\tvalid_0's multi_error: 0.32585\n",
      "[742]\tvalid_0's multi_error: 0.325872\n",
      "[743]\tvalid_0's multi_error: 0.325983\n",
      "[744]\tvalid_0's multi_error: 0.326005\n",
      "[745]\tvalid_0's multi_error: 0.326116\n",
      "[746]\tvalid_0's multi_error: 0.326228\n",
      "[747]\tvalid_0's multi_error: 0.326316\n",
      "[748]\tvalid_0's multi_error: 0.326383\n",
      "[749]\tvalid_0's multi_error: 0.326383\n",
      "[750]\tvalid_0's multi_error: 0.32645\n",
      "[751]\tvalid_0's multi_error: 0.326272\n",
      "[752]\tvalid_0's multi_error: 0.326161\n",
      "[753]\tvalid_0's multi_error: 0.326316\n",
      "[754]\tvalid_0's multi_error: 0.326428\n",
      "[755]\tvalid_0's multi_error: 0.326472\n",
      "[756]\tvalid_0's multi_error: 0.326361\n",
      "[757]\tvalid_0's multi_error: 0.326139\n",
      "[758]\tvalid_0's multi_error: 0.32605\n",
      "[759]\tvalid_0's multi_error: 0.325894\n",
      "[760]\tvalid_0's multi_error: 0.325894\n",
      "[761]\tvalid_0's multi_error: 0.326005\n",
      "[762]\tvalid_0's multi_error: 0.32605\n",
      "[763]\tvalid_0's multi_error: 0.326228\n",
      "[764]\tvalid_0's multi_error: 0.326183\n",
      "[765]\tvalid_0's multi_error: 0.325961\n",
      "[766]\tvalid_0's multi_error: 0.326028\n",
      "[767]\tvalid_0's multi_error: 0.325916\n",
      "[768]\tvalid_0's multi_error: 0.325827\n",
      "[769]\tvalid_0's multi_error: 0.325761\n",
      "[770]\tvalid_0's multi_error: 0.325672\n",
      "[771]\tvalid_0's multi_error: 0.325761\n",
      "[772]\tvalid_0's multi_error: 0.325783\n",
      "[773]\tvalid_0's multi_error: 0.325827\n",
      "[774]\tvalid_0's multi_error: 0.325827\n",
      "[775]\tvalid_0's multi_error: 0.326005\n",
      "[776]\tvalid_0's multi_error: 0.325961\n",
      "[777]\tvalid_0's multi_error: 0.326005\n",
      "[778]\tvalid_0's multi_error: 0.325783\n",
      "[779]\tvalid_0's multi_error: 0.325872\n",
      "[780]\tvalid_0's multi_error: 0.325805\n",
      "[781]\tvalid_0's multi_error: 0.32605\n",
      "[782]\tvalid_0's multi_error: 0.326005\n",
      "[783]\tvalid_0's multi_error: 0.326005\n",
      "[784]\tvalid_0's multi_error: 0.325894\n",
      "[785]\tvalid_0's multi_error: 0.325894\n",
      "[786]\tvalid_0's multi_error: 0.326005\n",
      "[787]\tvalid_0's multi_error: 0.325961\n",
      "[788]\tvalid_0's multi_error: 0.326094\n",
      "[789]\tvalid_0's multi_error: 0.326139\n",
      "[790]\tvalid_0's multi_error: 0.326161\n",
      "[791]\tvalid_0's multi_error: 0.326339\n",
      "[792]\tvalid_0's multi_error: 0.326116\n",
      "[793]\tvalid_0's multi_error: 0.326183\n",
      "[794]\tvalid_0's multi_error: 0.326339\n",
      "[795]\tvalid_0's multi_error: 0.326183\n",
      "[796]\tvalid_0's multi_error: 0.32605\n",
      "[797]\tvalid_0's multi_error: 0.325961\n",
      "[798]\tvalid_0's multi_error: 0.325916\n",
      "[799]\tvalid_0's multi_error: 0.325739\n",
      "[800]\tvalid_0's multi_error: 0.325627\n",
      "[801]\tvalid_0's multi_error: 0.325561\n",
      "[802]\tvalid_0's multi_error: 0.325405\n",
      "[803]\tvalid_0's multi_error: 0.325494\n",
      "[804]\tvalid_0's multi_error: 0.325739\n",
      "[805]\tvalid_0's multi_error: 0.325761\n",
      "[806]\tvalid_0's multi_error: 0.325672\n",
      "[807]\tvalid_0's multi_error: 0.325672\n",
      "[808]\tvalid_0's multi_error: 0.325627\n",
      "[809]\tvalid_0's multi_error: 0.32565\n",
      "[810]\tvalid_0's multi_error: 0.325627\n",
      "[811]\tvalid_0's multi_error: 0.325583\n",
      "[812]\tvalid_0's multi_error: 0.325627\n",
      "[813]\tvalid_0's multi_error: 0.32565\n",
      "[814]\tvalid_0's multi_error: 0.325739\n",
      "[815]\tvalid_0's multi_error: 0.325694\n",
      "[816]\tvalid_0's multi_error: 0.325694\n",
      "[817]\tvalid_0's multi_error: 0.325805\n",
      "[818]\tvalid_0's multi_error: 0.325827\n",
      "[819]\tvalid_0's multi_error: 0.325939\n",
      "[820]\tvalid_0's multi_error: 0.325916\n",
      "[821]\tvalid_0's multi_error: 0.326028\n",
      "[822]\tvalid_0's multi_error: 0.325916\n",
      "[823]\tvalid_0's multi_error: 0.325939\n",
      "[824]\tvalid_0's multi_error: 0.32585\n",
      "[825]\tvalid_0's multi_error: 0.325761\n",
      "[826]\tvalid_0's multi_error: 0.325894\n",
      "[827]\tvalid_0's multi_error: 0.325716\n",
      "[828]\tvalid_0's multi_error: 0.325827\n",
      "[829]\tvalid_0's multi_error: 0.325761\n",
      "[830]\tvalid_0's multi_error: 0.325805\n",
      "[831]\tvalid_0's multi_error: 0.325872\n",
      "[832]\tvalid_0's multi_error: 0.32585\n",
      "[833]\tvalid_0's multi_error: 0.325783\n",
      "[834]\tvalid_0's multi_error: 0.325783\n",
      "[835]\tvalid_0's multi_error: 0.325694\n",
      "[836]\tvalid_0's multi_error: 0.325761\n",
      "[837]\tvalid_0's multi_error: 0.32585\n",
      "[838]\tvalid_0's multi_error: 0.325827\n",
      "[839]\tvalid_0's multi_error: 0.325894\n",
      "[840]\tvalid_0's multi_error: 0.32585\n",
      "[841]\tvalid_0's multi_error: 0.325805\n",
      "[842]\tvalid_0's multi_error: 0.325961\n",
      "[843]\tvalid_0's multi_error: 0.326005\n",
      "[844]\tvalid_0's multi_error: 0.325939\n",
      "[845]\tvalid_0's multi_error: 0.325961\n",
      "[846]\tvalid_0's multi_error: 0.326161\n",
      "[847]\tvalid_0's multi_error: 0.326228\n",
      "[848]\tvalid_0's multi_error: 0.326161\n",
      "[849]\tvalid_0's multi_error: 0.326094\n",
      "[850]\tvalid_0's multi_error: 0.325961\n",
      "[851]\tvalid_0's multi_error: 0.325961\n",
      "[852]\tvalid_0's multi_error: 0.325983\n",
      "[853]\tvalid_0's multi_error: 0.325805\n",
      "[854]\tvalid_0's multi_error: 0.325739\n",
      "[855]\tvalid_0's multi_error: 0.32565\n",
      "[856]\tvalid_0's multi_error: 0.325716\n",
      "[857]\tvalid_0's multi_error: 0.32585\n",
      "[858]\tvalid_0's multi_error: 0.325939\n",
      "[859]\tvalid_0's multi_error: 0.325939\n",
      "[860]\tvalid_0's multi_error: 0.325805\n",
      "[861]\tvalid_0's multi_error: 0.325672\n",
      "[862]\tvalid_0's multi_error: 0.325827\n",
      "[863]\tvalid_0's multi_error: 0.32585\n",
      "[864]\tvalid_0's multi_error: 0.32585\n",
      "[865]\tvalid_0's multi_error: 0.325872\n",
      "[866]\tvalid_0's multi_error: 0.325894\n",
      "[867]\tvalid_0's multi_error: 0.326005\n",
      "[868]\tvalid_0's multi_error: 0.326183\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[869]\tvalid_0's multi_error: 0.326094\n",
      "[870]\tvalid_0's multi_error: 0.326005\n",
      "[871]\tvalid_0's multi_error: 0.326116\n",
      "[872]\tvalid_0's multi_error: 0.325983\n",
      "[873]\tvalid_0's multi_error: 0.32605\n",
      "[874]\tvalid_0's multi_error: 0.326005\n",
      "[875]\tvalid_0's multi_error: 0.32605\n",
      "[876]\tvalid_0's multi_error: 0.326005\n",
      "[877]\tvalid_0's multi_error: 0.325961\n",
      "[878]\tvalid_0's multi_error: 0.325805\n",
      "[879]\tvalid_0's multi_error: 0.32585\n",
      "[880]\tvalid_0's multi_error: 0.32585\n",
      "[881]\tvalid_0's multi_error: 0.325716\n",
      "[882]\tvalid_0's multi_error: 0.32565\n",
      "[883]\tvalid_0's multi_error: 0.325694\n",
      "[884]\tvalid_0's multi_error: 0.325761\n",
      "[885]\tvalid_0's multi_error: 0.325761\n",
      "[886]\tvalid_0's multi_error: 0.325672\n",
      "[887]\tvalid_0's multi_error: 0.32585\n",
      "[888]\tvalid_0's multi_error: 0.32605\n",
      "[889]\tvalid_0's multi_error: 0.326161\n",
      "[890]\tvalid_0's multi_error: 0.32605\n",
      "[891]\tvalid_0's multi_error: 0.32605\n",
      "[892]\tvalid_0's multi_error: 0.325939\n",
      "[893]\tvalid_0's multi_error: 0.326139\n",
      "[894]\tvalid_0's multi_error: 0.326139\n",
      "[895]\tvalid_0's multi_error: 0.326028\n",
      "[896]\tvalid_0's multi_error: 0.325961\n",
      "[897]\tvalid_0's multi_error: 0.325983\n",
      "[898]\tvalid_0's multi_error: 0.326028\n",
      "[899]\tvalid_0's multi_error: 0.325983\n",
      "[900]\tvalid_0's multi_error: 0.326005\n",
      "[901]\tvalid_0's multi_error: 0.325872\n",
      "[902]\tvalid_0's multi_error: 0.325827\n",
      "[903]\tvalid_0's multi_error: 0.325894\n",
      "[904]\tvalid_0's multi_error: 0.325761\n",
      "[905]\tvalid_0's multi_error: 0.325583\n",
      "[906]\tvalid_0's multi_error: 0.32565\n",
      "[907]\tvalid_0's multi_error: 0.325716\n",
      "[908]\tvalid_0's multi_error: 0.325739\n",
      "[909]\tvalid_0's multi_error: 0.325961\n",
      "[910]\tvalid_0's multi_error: 0.326005\n",
      "[911]\tvalid_0's multi_error: 0.326116\n",
      "[912]\tvalid_0's multi_error: 0.326116\n",
      "[913]\tvalid_0's multi_error: 0.326028\n",
      "[914]\tvalid_0's multi_error: 0.326028\n",
      "[915]\tvalid_0's multi_error: 0.326005\n",
      "[916]\tvalid_0's multi_error: 0.326005\n",
      "[917]\tvalid_0's multi_error: 0.326072\n",
      "[918]\tvalid_0's multi_error: 0.325939\n",
      "[919]\tvalid_0's multi_error: 0.326139\n",
      "[920]\tvalid_0's multi_error: 0.326028\n",
      "[921]\tvalid_0's multi_error: 0.326028\n",
      "[922]\tvalid_0's multi_error: 0.325939\n",
      "[923]\tvalid_0's multi_error: 0.325939\n",
      "[924]\tvalid_0's multi_error: 0.325783\n",
      "[925]\tvalid_0's multi_error: 0.325716\n",
      "[926]\tvalid_0's multi_error: 0.325939\n",
      "[927]\tvalid_0's multi_error: 0.325916\n",
      "[928]\tvalid_0's multi_error: 0.325827\n",
      "[929]\tvalid_0's multi_error: 0.32565\n",
      "[930]\tvalid_0's multi_error: 0.325916\n",
      "[931]\tvalid_0's multi_error: 0.326072\n",
      "[932]\tvalid_0's multi_error: 0.326116\n",
      "[933]\tvalid_0's multi_error: 0.326028\n",
      "[934]\tvalid_0's multi_error: 0.326094\n",
      "[935]\tvalid_0's multi_error: 0.32625\n",
      "[936]\tvalid_0's multi_error: 0.325983\n",
      "[937]\tvalid_0's multi_error: 0.326072\n",
      "[938]\tvalid_0's multi_error: 0.326005\n",
      "[939]\tvalid_0's multi_error: 0.325872\n",
      "[940]\tvalid_0's multi_error: 0.325894\n",
      "[941]\tvalid_0's multi_error: 0.325783\n",
      "[942]\tvalid_0's multi_error: 0.325805\n",
      "[943]\tvalid_0's multi_error: 0.325783\n",
      "[944]\tvalid_0's multi_error: 0.325827\n",
      "[945]\tvalid_0's multi_error: 0.325761\n",
      "[946]\tvalid_0's multi_error: 0.325805\n",
      "[947]\tvalid_0's multi_error: 0.325783\n",
      "[948]\tvalid_0's multi_error: 0.325472\n",
      "[949]\tvalid_0's multi_error: 0.325538\n",
      "[950]\tvalid_0's multi_error: 0.325605\n",
      "[951]\tvalid_0's multi_error: 0.325872\n",
      "[952]\tvalid_0's multi_error: 0.326005\n",
      "[953]\tvalid_0's multi_error: 0.325872\n",
      "[954]\tvalid_0's multi_error: 0.325939\n",
      "[955]\tvalid_0's multi_error: 0.325894\n",
      "[956]\tvalid_0's multi_error: 0.325716\n",
      "[957]\tvalid_0's multi_error: 0.325739\n",
      "[958]\tvalid_0's multi_error: 0.325761\n",
      "[959]\tvalid_0's multi_error: 0.32585\n",
      "[960]\tvalid_0's multi_error: 0.325805\n",
      "[961]\tvalid_0's multi_error: 0.32585\n",
      "[962]\tvalid_0's multi_error: 0.325716\n",
      "[963]\tvalid_0's multi_error: 0.325583\n",
      "[964]\tvalid_0's multi_error: 0.325561\n",
      "[965]\tvalid_0's multi_error: 0.325694\n",
      "[966]\tvalid_0's multi_error: 0.325538\n",
      "[967]\tvalid_0's multi_error: 0.325672\n",
      "[968]\tvalid_0's multi_error: 0.325583\n",
      "[969]\tvalid_0's multi_error: 0.325583\n",
      "[970]\tvalid_0's multi_error: 0.325627\n",
      "[971]\tvalid_0's multi_error: 0.325716\n",
      "[972]\tvalid_0's multi_error: 0.325739\n",
      "[973]\tvalid_0's multi_error: 0.325672\n",
      "[974]\tvalid_0's multi_error: 0.325561\n",
      "[975]\tvalid_0's multi_error: 0.325739\n",
      "[976]\tvalid_0's multi_error: 0.325427\n",
      "[977]\tvalid_0's multi_error: 0.325561\n",
      "[978]\tvalid_0's multi_error: 0.32545\n",
      "[979]\tvalid_0's multi_error: 0.32545\n",
      "[980]\tvalid_0's multi_error: 0.32565\n",
      "[981]\tvalid_0's multi_error: 0.325783\n",
      "[982]\tvalid_0's multi_error: 0.325827\n",
      "[983]\tvalid_0's multi_error: 0.325783\n",
      "[984]\tvalid_0's multi_error: 0.325739\n",
      "[985]\tvalid_0's multi_error: 0.325716\n",
      "[986]\tvalid_0's multi_error: 0.325739\n",
      "[987]\tvalid_0's multi_error: 0.325827\n",
      "[988]\tvalid_0's multi_error: 0.32565\n",
      "[989]\tvalid_0's multi_error: 0.325672\n",
      "[990]\tvalid_0's multi_error: 0.325538\n",
      "[991]\tvalid_0's multi_error: 0.325538\n",
      "[992]\tvalid_0's multi_error: 0.325494\n",
      "[993]\tvalid_0's multi_error: 0.325494\n",
      "[994]\tvalid_0's multi_error: 0.325494\n",
      "[995]\tvalid_0's multi_error: 0.325494\n",
      "[996]\tvalid_0's multi_error: 0.325561\n",
      "[997]\tvalid_0's multi_error: 0.32565\n",
      "[998]\tvalid_0's multi_error: 0.325605\n",
      "[999]\tvalid_0's multi_error: 0.325605\n",
      "[1000]\tvalid_0's multi_error: 0.325561\n",
      "[1001]\tvalid_0's multi_error: 0.325627\n",
      "[1002]\tvalid_0's multi_error: 0.325561\n",
      "[1003]\tvalid_0's multi_error: 0.325605\n",
      "[1004]\tvalid_0's multi_error: 0.325561\n",
      "[1005]\tvalid_0's multi_error: 0.325472\n",
      "[1006]\tvalid_0's multi_error: 0.325383\n",
      "[1007]\tvalid_0's multi_error: 0.325472\n",
      "[1008]\tvalid_0's multi_error: 0.325472\n",
      "[1009]\tvalid_0's multi_error: 0.325538\n",
      "[1010]\tvalid_0's multi_error: 0.325538\n",
      "[1011]\tvalid_0's multi_error: 0.325494\n",
      "[1012]\tvalid_0's multi_error: 0.325361\n",
      "[1013]\tvalid_0's multi_error: 0.325405\n",
      "[1014]\tvalid_0's multi_error: 0.325427\n",
      "[1015]\tvalid_0's multi_error: 0.325227\n",
      "[1016]\tvalid_0's multi_error: 0.325116\n",
      "[1017]\tvalid_0's multi_error: 0.325227\n",
      "[1018]\tvalid_0's multi_error: 0.325205\n",
      "[1019]\tvalid_0's multi_error: 0.325272\n",
      "[1020]\tvalid_0's multi_error: 0.325205\n",
      "[1021]\tvalid_0's multi_error: 0.325272\n",
      "[1022]\tvalid_0's multi_error: 0.32525\n",
      "[1023]\tvalid_0's multi_error: 0.325316\n",
      "[1024]\tvalid_0's multi_error: 0.325272\n",
      "[1025]\tvalid_0's multi_error: 0.32525\n",
      "[1026]\tvalid_0's multi_error: 0.325116\n",
      "[1027]\tvalid_0's multi_error: 0.325183\n",
      "[1028]\tvalid_0's multi_error: 0.325205\n",
      "[1029]\tvalid_0's multi_error: 0.325116\n",
      "[1030]\tvalid_0's multi_error: 0.325161\n",
      "[1031]\tvalid_0's multi_error: 0.325049\n",
      "[1032]\tvalid_0's multi_error: 0.324938\n",
      "[1033]\tvalid_0's multi_error: 0.325005\n",
      "[1034]\tvalid_0's multi_error: 0.324938\n",
      "[1035]\tvalid_0's multi_error: 0.324938\n",
      "[1036]\tvalid_0's multi_error: 0.324894\n",
      "[1037]\tvalid_0's multi_error: 0.324894\n",
      "[1038]\tvalid_0's multi_error: 0.324961\n",
      "[1039]\tvalid_0's multi_error: 0.325072\n",
      "[1040]\tvalid_0's multi_error: 0.324916\n",
      "[1041]\tvalid_0's multi_error: 0.324983\n",
      "[1042]\tvalid_0's multi_error: 0.324938\n",
      "[1043]\tvalid_0's multi_error: 0.325227\n",
      "[1044]\tvalid_0's multi_error: 0.325272\n",
      "[1045]\tvalid_0's multi_error: 0.325361\n",
      "[1046]\tvalid_0's multi_error: 0.325316\n",
      "[1047]\tvalid_0's multi_error: 0.325472\n",
      "[1048]\tvalid_0's multi_error: 0.325494\n",
      "[1049]\tvalid_0's multi_error: 0.325338\n",
      "[1050]\tvalid_0's multi_error: 0.325227\n",
      "[1051]\tvalid_0's multi_error: 0.325138\n",
      "[1052]\tvalid_0's multi_error: 0.324983\n",
      "[1053]\tvalid_0's multi_error: 0.325183\n",
      "[1054]\tvalid_0's multi_error: 0.325205\n",
      "[1055]\tvalid_0's multi_error: 0.325205\n",
      "[1056]\tvalid_0's multi_error: 0.325272\n",
      "[1057]\tvalid_0's multi_error: 0.325161\n",
      "[1058]\tvalid_0's multi_error: 0.325005\n",
      "[1059]\tvalid_0's multi_error: 0.325027\n",
      "[1060]\tvalid_0's multi_error: 0.324961\n",
      "[1061]\tvalid_0's multi_error: 0.324938\n",
      "[1062]\tvalid_0's multi_error: 0.324894\n",
      "[1063]\tvalid_0's multi_error: 0.324961\n",
      "[1064]\tvalid_0's multi_error: 0.325005\n",
      "[1065]\tvalid_0's multi_error: 0.325072\n",
      "[1066]\tvalid_0's multi_error: 0.325116\n",
      "[1067]\tvalid_0's multi_error: 0.324961\n",
      "[1068]\tvalid_0's multi_error: 0.324938\n",
      "[1069]\tvalid_0's multi_error: 0.324872\n",
      "[1070]\tvalid_0's multi_error: 0.324916\n",
      "[1071]\tvalid_0's multi_error: 0.324716\n",
      "[1072]\tvalid_0's multi_error: 0.324872\n",
      "[1073]\tvalid_0's multi_error: 0.324916\n",
      "[1074]\tvalid_0's multi_error: 0.324916\n",
      "[1075]\tvalid_0's multi_error: 0.325161\n",
      "[1076]\tvalid_0's multi_error: 0.325183\n",
      "[1077]\tvalid_0's multi_error: 0.325138\n",
      "[1078]\tvalid_0's multi_error: 0.325161\n",
      "[1079]\tvalid_0's multi_error: 0.325116\n",
      "[1080]\tvalid_0's multi_error: 0.325138\n",
      "[1081]\tvalid_0's multi_error: 0.325094\n",
      "[1082]\tvalid_0's multi_error: 0.325027\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1083]\tvalid_0's multi_error: 0.324916\n",
      "[1084]\tvalid_0's multi_error: 0.324938\n",
      "[1085]\tvalid_0's multi_error: 0.324983\n",
      "[1086]\tvalid_0's multi_error: 0.325072\n",
      "[1087]\tvalid_0's multi_error: 0.325005\n",
      "[1088]\tvalid_0's multi_error: 0.325072\n",
      "[1089]\tvalid_0's multi_error: 0.325116\n",
      "[1090]\tvalid_0's multi_error: 0.324983\n",
      "[1091]\tvalid_0's multi_error: 0.324961\n",
      "[1092]\tvalid_0's multi_error: 0.324938\n",
      "[1093]\tvalid_0's multi_error: 0.324961\n",
      "[1094]\tvalid_0's multi_error: 0.324872\n",
      "[1095]\tvalid_0's multi_error: 0.324849\n",
      "[1096]\tvalid_0's multi_error: 0.324849\n",
      "[1097]\tvalid_0's multi_error: 0.324938\n",
      "[1098]\tvalid_0's multi_error: 0.324983\n",
      "[1099]\tvalid_0's multi_error: 0.324916\n",
      "[1100]\tvalid_0's multi_error: 0.325049\n",
      "[1101]\tvalid_0's multi_error: 0.324983\n",
      "[1102]\tvalid_0's multi_error: 0.325072\n",
      "[1103]\tvalid_0's multi_error: 0.325072\n",
      "[1104]\tvalid_0's multi_error: 0.325116\n",
      "[1105]\tvalid_0's multi_error: 0.324938\n",
      "[1106]\tvalid_0's multi_error: 0.325138\n",
      "[1107]\tvalid_0's multi_error: 0.325183\n",
      "[1108]\tvalid_0's multi_error: 0.325383\n",
      "[1109]\tvalid_0's multi_error: 0.325427\n",
      "[1110]\tvalid_0's multi_error: 0.32545\n",
      "[1111]\tvalid_0's multi_error: 0.325538\n",
      "[1112]\tvalid_0's multi_error: 0.325494\n",
      "[1113]\tvalid_0's multi_error: 0.325427\n",
      "[1114]\tvalid_0's multi_error: 0.325294\n",
      "[1115]\tvalid_0's multi_error: 0.325205\n",
      "[1116]\tvalid_0's multi_error: 0.325094\n",
      "[1117]\tvalid_0's multi_error: 0.325027\n",
      "[1118]\tvalid_0's multi_error: 0.325116\n",
      "[1119]\tvalid_0's multi_error: 0.325005\n",
      "[1120]\tvalid_0's multi_error: 0.325027\n",
      "[1121]\tvalid_0's multi_error: 0.324894\n",
      "[1122]\tvalid_0's multi_error: 0.324849\n",
      "[1123]\tvalid_0's multi_error: 0.324872\n",
      "[1124]\tvalid_0's multi_error: 0.324916\n",
      "[1125]\tvalid_0's multi_error: 0.325049\n",
      "[1126]\tvalid_0's multi_error: 0.325138\n",
      "[1127]\tvalid_0's multi_error: 0.325005\n",
      "[1128]\tvalid_0's multi_error: 0.325005\n",
      "[1129]\tvalid_0's multi_error: 0.324983\n",
      "[1130]\tvalid_0's multi_error: 0.325005\n",
      "[1131]\tvalid_0's multi_error: 0.325005\n",
      "[1132]\tvalid_0's multi_error: 0.325072\n",
      "[1133]\tvalid_0's multi_error: 0.325049\n",
      "[1134]\tvalid_0's multi_error: 0.325027\n",
      "[1135]\tvalid_0's multi_error: 0.325049\n",
      "[1136]\tvalid_0's multi_error: 0.325072\n",
      "[1137]\tvalid_0's multi_error: 0.325138\n",
      "[1138]\tvalid_0's multi_error: 0.325138\n",
      "[1139]\tvalid_0's multi_error: 0.325161\n",
      "[1140]\tvalid_0's multi_error: 0.325072\n",
      "[1141]\tvalid_0's multi_error: 0.325116\n",
      "[1142]\tvalid_0's multi_error: 0.325183\n",
      "[1143]\tvalid_0's multi_error: 0.325161\n",
      "[1144]\tvalid_0's multi_error: 0.32525\n",
      "[1145]\tvalid_0's multi_error: 0.325338\n",
      "[1146]\tvalid_0's multi_error: 0.32525\n",
      "[1147]\tvalid_0's multi_error: 0.325294\n",
      "[1148]\tvalid_0's multi_error: 0.325227\n",
      "[1149]\tvalid_0's multi_error: 0.325116\n",
      "[1150]\tvalid_0's multi_error: 0.325116\n",
      "[1151]\tvalid_0's multi_error: 0.325138\n",
      "[1152]\tvalid_0's multi_error: 0.325338\n",
      "[1153]\tvalid_0's multi_error: 0.325338\n",
      "[1154]\tvalid_0's multi_error: 0.325561\n",
      "[1155]\tvalid_0's multi_error: 0.32545\n",
      "[1156]\tvalid_0's multi_error: 0.325383\n",
      "[1157]\tvalid_0's multi_error: 0.325538\n",
      "[1158]\tvalid_0's multi_error: 0.32545\n",
      "[1159]\tvalid_0's multi_error: 0.325383\n",
      "[1160]\tvalid_0's multi_error: 0.325338\n",
      "[1161]\tvalid_0's multi_error: 0.325538\n",
      "[1162]\tvalid_0's multi_error: 0.32545\n",
      "[1163]\tvalid_0's multi_error: 0.325516\n",
      "[1164]\tvalid_0's multi_error: 0.325716\n",
      "[1165]\tvalid_0's multi_error: 0.32565\n",
      "[1166]\tvalid_0's multi_error: 0.325494\n",
      "[1167]\tvalid_0's multi_error: 0.32545\n",
      "[1168]\tvalid_0's multi_error: 0.325383\n",
      "[1169]\tvalid_0's multi_error: 0.325405\n",
      "[1170]\tvalid_0's multi_error: 0.325494\n",
      "[1171]\tvalid_0's multi_error: 0.32545\n",
      "[1172]\tvalid_0's multi_error: 0.325494\n",
      "[1173]\tvalid_0's multi_error: 0.325494\n",
      "[1174]\tvalid_0's multi_error: 0.325472\n",
      "[1175]\tvalid_0's multi_error: 0.325516\n",
      "[1176]\tvalid_0's multi_error: 0.32525\n",
      "[1177]\tvalid_0's multi_error: 0.325227\n",
      "[1178]\tvalid_0's multi_error: 0.325294\n",
      "[1179]\tvalid_0's multi_error: 0.325272\n",
      "[1180]\tvalid_0's multi_error: 0.325383\n",
      "[1181]\tvalid_0's multi_error: 0.325427\n",
      "[1182]\tvalid_0's multi_error: 0.325383\n",
      "[1183]\tvalid_0's multi_error: 0.32545\n",
      "[1184]\tvalid_0's multi_error: 0.325561\n",
      "[1185]\tvalid_0's multi_error: 0.325672\n",
      "[1186]\tvalid_0's multi_error: 0.325672\n",
      "[1187]\tvalid_0's multi_error: 0.32585\n",
      "[1188]\tvalid_0's multi_error: 0.325872\n",
      "[1189]\tvalid_0's multi_error: 0.325739\n",
      "[1190]\tvalid_0's multi_error: 0.325627\n",
      "[1191]\tvalid_0's multi_error: 0.325694\n",
      "[1192]\tvalid_0's multi_error: 0.32565\n",
      "[1193]\tvalid_0's multi_error: 0.325627\n",
      "[1194]\tvalid_0's multi_error: 0.325694\n",
      "[1195]\tvalid_0's multi_error: 0.32565\n",
      "[1196]\tvalid_0's multi_error: 0.325605\n",
      "[1197]\tvalid_0's multi_error: 0.325427\n",
      "[1198]\tvalid_0's multi_error: 0.325383\n",
      "[1199]\tvalid_0's multi_error: 0.325183\n",
      "[1200]\tvalid_0's multi_error: 0.325049\n",
      "[1201]\tvalid_0's multi_error: 0.325027\n",
      "[1202]\tvalid_0's multi_error: 0.324827\n",
      "[1203]\tvalid_0's multi_error: 0.324805\n",
      "[1204]\tvalid_0's multi_error: 0.32476\n",
      "[1205]\tvalid_0's multi_error: 0.324872\n",
      "[1206]\tvalid_0's multi_error: 0.324983\n",
      "[1207]\tvalid_0's multi_error: 0.324983\n",
      "[1208]\tvalid_0's multi_error: 0.325138\n",
      "[1209]\tvalid_0's multi_error: 0.325027\n",
      "[1210]\tvalid_0's multi_error: 0.325072\n",
      "[1211]\tvalid_0's multi_error: 0.325094\n",
      "[1212]\tvalid_0's multi_error: 0.325294\n",
      "[1213]\tvalid_0's multi_error: 0.325272\n",
      "[1214]\tvalid_0's multi_error: 0.325338\n",
      "[1215]\tvalid_0's multi_error: 0.32545\n",
      "[1216]\tvalid_0's multi_error: 0.32545\n",
      "[1217]\tvalid_0's multi_error: 0.325405\n",
      "[1218]\tvalid_0's multi_error: 0.325294\n",
      "[1219]\tvalid_0's multi_error: 0.325316\n",
      "[1220]\tvalid_0's multi_error: 0.325316\n",
      "[1221]\tvalid_0's multi_error: 0.325338\n",
      "[1222]\tvalid_0's multi_error: 0.325427\n",
      "[1223]\tvalid_0's multi_error: 0.325494\n",
      "[1224]\tvalid_0's multi_error: 0.325516\n",
      "[1225]\tvalid_0's multi_error: 0.325605\n",
      "[1226]\tvalid_0's multi_error: 0.32565\n",
      "[1227]\tvalid_0's multi_error: 0.325561\n",
      "[1228]\tvalid_0's multi_error: 0.325516\n",
      "[1229]\tvalid_0's multi_error: 0.325583\n",
      "[1230]\tvalid_0's multi_error: 0.325672\n",
      "[1231]\tvalid_0's multi_error: 0.325583\n",
      "[1232]\tvalid_0's multi_error: 0.325627\n",
      "[1233]\tvalid_0's multi_error: 0.325605\n",
      "[1234]\tvalid_0's multi_error: 0.325694\n",
      "[1235]\tvalid_0's multi_error: 0.325605\n",
      "[1236]\tvalid_0's multi_error: 0.325472\n",
      "[1237]\tvalid_0's multi_error: 0.325538\n",
      "[1238]\tvalid_0's multi_error: 0.325516\n",
      "[1239]\tvalid_0's multi_error: 0.325516\n",
      "[1240]\tvalid_0's multi_error: 0.32565\n",
      "[1241]\tvalid_0's multi_error: 0.325538\n",
      "[1242]\tvalid_0's multi_error: 0.325494\n",
      "[1243]\tvalid_0's multi_error: 0.325472\n",
      "[1244]\tvalid_0's multi_error: 0.325272\n",
      "[1245]\tvalid_0's multi_error: 0.325383\n",
      "[1246]\tvalid_0's multi_error: 0.325383\n",
      "[1247]\tvalid_0's multi_error: 0.325338\n",
      "[1248]\tvalid_0's multi_error: 0.325316\n",
      "[1249]\tvalid_0's multi_error: 0.325361\n",
      "[1250]\tvalid_0's multi_error: 0.325272\n",
      "[1251]\tvalid_0's multi_error: 0.325338\n",
      "[1252]\tvalid_0's multi_error: 0.325561\n",
      "[1253]\tvalid_0's multi_error: 0.325672\n",
      "[1254]\tvalid_0's multi_error: 0.325672\n",
      "[1255]\tvalid_0's multi_error: 0.32565\n",
      "[1256]\tvalid_0's multi_error: 0.325605\n",
      "[1257]\tvalid_0's multi_error: 0.325694\n",
      "[1258]\tvalid_0's multi_error: 0.325827\n",
      "[1259]\tvalid_0's multi_error: 0.325694\n",
      "[1260]\tvalid_0's multi_error: 0.325561\n",
      "[1261]\tvalid_0's multi_error: 0.325605\n",
      "[1262]\tvalid_0's multi_error: 0.325516\n",
      "[1263]\tvalid_0's multi_error: 0.325694\n",
      "[1264]\tvalid_0's multi_error: 0.325672\n",
      "[1265]\tvalid_0's multi_error: 0.32565\n",
      "[1266]\tvalid_0's multi_error: 0.325605\n",
      "[1267]\tvalid_0's multi_error: 0.325538\n",
      "[1268]\tvalid_0's multi_error: 0.32545\n",
      "[1269]\tvalid_0's multi_error: 0.325338\n",
      "[1270]\tvalid_0's multi_error: 0.325538\n",
      "[1271]\tvalid_0's multi_error: 0.325494\n",
      "[1272]\tvalid_0's multi_error: 0.325361\n",
      "[1273]\tvalid_0's multi_error: 0.325383\n",
      "[1274]\tvalid_0's multi_error: 0.32525\n",
      "[1275]\tvalid_0's multi_error: 0.325361\n",
      "[1276]\tvalid_0's multi_error: 0.325427\n",
      "[1277]\tvalid_0's multi_error: 0.325494\n",
      "[1278]\tvalid_0's multi_error: 0.325205\n",
      "[1279]\tvalid_0's multi_error: 0.325294\n",
      "[1280]\tvalid_0's multi_error: 0.325538\n",
      "[1281]\tvalid_0's multi_error: 0.325383\n",
      "[1282]\tvalid_0's multi_error: 0.325694\n",
      "[1283]\tvalid_0's multi_error: 0.32565\n",
      "[1284]\tvalid_0's multi_error: 0.325561\n",
      "[1285]\tvalid_0's multi_error: 0.325605\n",
      "[1286]\tvalid_0's multi_error: 0.325739\n",
      "[1287]\tvalid_0's multi_error: 0.325716\n",
      "[1288]\tvalid_0's multi_error: 0.325583\n",
      "[1289]\tvalid_0's multi_error: 0.325783\n",
      "[1290]\tvalid_0's multi_error: 0.325761\n",
      "[1291]\tvalid_0's multi_error: 0.325939\n",
      "[1292]\tvalid_0's multi_error: 0.325939\n",
      "[1293]\tvalid_0's multi_error: 0.325939\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1294]\tvalid_0's multi_error: 0.325783\n",
      "[1295]\tvalid_0's multi_error: 0.325783\n",
      "[1296]\tvalid_0's multi_error: 0.325827\n",
      "[1297]\tvalid_0's multi_error: 0.325694\n",
      "[1298]\tvalid_0's multi_error: 0.325694\n",
      "[1299]\tvalid_0's multi_error: 0.325583\n",
      "[1300]\tvalid_0's multi_error: 0.325561\n",
      "[1301]\tvalid_0's multi_error: 0.325538\n",
      "[1302]\tvalid_0's multi_error: 0.32565\n",
      "[1303]\tvalid_0's multi_error: 0.325583\n",
      "[1304]\tvalid_0's multi_error: 0.325494\n",
      "[1305]\tvalid_0's multi_error: 0.32545\n",
      "[1306]\tvalid_0's multi_error: 0.32545\n",
      "[1307]\tvalid_0's multi_error: 0.325494\n",
      "[1308]\tvalid_0's multi_error: 0.325605\n",
      "[1309]\tvalid_0's multi_error: 0.325605\n",
      "[1310]\tvalid_0's multi_error: 0.325672\n",
      "[1311]\tvalid_0's multi_error: 0.325583\n",
      "[1312]\tvalid_0's multi_error: 0.325605\n",
      "[1313]\tvalid_0's multi_error: 0.325516\n",
      "[1314]\tvalid_0's multi_error: 0.325627\n",
      "[1315]\tvalid_0's multi_error: 0.325494\n",
      "[1316]\tvalid_0's multi_error: 0.325561\n",
      "[1317]\tvalid_0's multi_error: 0.325494\n",
      "[1318]\tvalid_0's multi_error: 0.325672\n",
      "[1319]\tvalid_0's multi_error: 0.325694\n",
      "[1320]\tvalid_0's multi_error: 0.325561\n",
      "[1321]\tvalid_0's multi_error: 0.325538\n",
      "[1322]\tvalid_0's multi_error: 0.325516\n",
      "[1323]\tvalid_0's multi_error: 0.325494\n",
      "[1324]\tvalid_0's multi_error: 0.325694\n",
      "[1325]\tvalid_0's multi_error: 0.325827\n",
      "[1326]\tvalid_0's multi_error: 0.32565\n",
      "[1327]\tvalid_0's multi_error: 0.325716\n",
      "[1328]\tvalid_0's multi_error: 0.325672\n",
      "[1329]\tvalid_0's multi_error: 0.325694\n",
      "[1330]\tvalid_0's multi_error: 0.325605\n",
      "[1331]\tvalid_0's multi_error: 0.325627\n",
      "[1332]\tvalid_0's multi_error: 0.325627\n",
      "[1333]\tvalid_0's multi_error: 0.325672\n",
      "[1334]\tvalid_0's multi_error: 0.325561\n",
      "[1335]\tvalid_0's multi_error: 0.325538\n",
      "[1336]\tvalid_0's multi_error: 0.325672\n",
      "[1337]\tvalid_0's multi_error: 0.32565\n",
      "[1338]\tvalid_0's multi_error: 0.325805\n",
      "[1339]\tvalid_0's multi_error: 0.325627\n",
      "[1340]\tvalid_0's multi_error: 0.325739\n",
      "[1341]\tvalid_0's multi_error: 0.325516\n",
      "[1342]\tvalid_0's multi_error: 0.325561\n",
      "[1343]\tvalid_0's multi_error: 0.325605\n",
      "[1344]\tvalid_0's multi_error: 0.325672\n",
      "[1345]\tvalid_0's multi_error: 0.325672\n",
      "[1346]\tvalid_0's multi_error: 0.325694\n",
      "[1347]\tvalid_0's multi_error: 0.325672\n",
      "[1348]\tvalid_0's multi_error: 0.325605\n",
      "[1349]\tvalid_0's multi_error: 0.325605\n",
      "[1350]\tvalid_0's multi_error: 0.325716\n",
      "[1351]\tvalid_0's multi_error: 0.325627\n",
      "[1352]\tvalid_0's multi_error: 0.325694\n",
      "[1353]\tvalid_0's multi_error: 0.325672\n",
      "[1354]\tvalid_0's multi_error: 0.325716\n",
      "[1355]\tvalid_0's multi_error: 0.325561\n",
      "[1356]\tvalid_0's multi_error: 0.325583\n",
      "[1357]\tvalid_0's multi_error: 0.325561\n",
      "[1358]\tvalid_0's multi_error: 0.325627\n",
      "[1359]\tvalid_0's multi_error: 0.325672\n",
      "[1360]\tvalid_0's multi_error: 0.325672\n",
      "[1361]\tvalid_0's multi_error: 0.325627\n",
      "[1362]\tvalid_0's multi_error: 0.325761\n",
      "[1363]\tvalid_0's multi_error: 0.325739\n",
      "[1364]\tvalid_0's multi_error: 0.325561\n",
      "[1365]\tvalid_0's multi_error: 0.325516\n",
      "[1366]\tvalid_0's multi_error: 0.325538\n",
      "[1367]\tvalid_0's multi_error: 0.32565\n",
      "[1368]\tvalid_0's multi_error: 0.325716\n",
      "[1369]\tvalid_0's multi_error: 0.325783\n",
      "[1370]\tvalid_0's multi_error: 0.325872\n",
      "[1371]\tvalid_0's multi_error: 0.325761\n",
      "[1372]\tvalid_0's multi_error: 0.325827\n",
      "[1373]\tvalid_0's multi_error: 0.325783\n",
      "[1374]\tvalid_0's multi_error: 0.325627\n",
      "[1375]\tvalid_0's multi_error: 0.325716\n",
      "[1376]\tvalid_0's multi_error: 0.325872\n",
      "[1377]\tvalid_0's multi_error: 0.325761\n",
      "[1378]\tvalid_0's multi_error: 0.325761\n",
      "[1379]\tvalid_0's multi_error: 0.325516\n",
      "[1380]\tvalid_0's multi_error: 0.32545\n",
      "[1381]\tvalid_0's multi_error: 0.325538\n",
      "[1382]\tvalid_0's multi_error: 0.325361\n",
      "[1383]\tvalid_0's multi_error: 0.325561\n",
      "[1384]\tvalid_0's multi_error: 0.325583\n",
      "[1385]\tvalid_0's multi_error: 0.325583\n",
      "[1386]\tvalid_0's multi_error: 0.325494\n",
      "[1387]\tvalid_0's multi_error: 0.32545\n",
      "[1388]\tvalid_0's multi_error: 0.325427\n",
      "[1389]\tvalid_0's multi_error: 0.325472\n",
      "[1390]\tvalid_0's multi_error: 0.32545\n",
      "[1391]\tvalid_0's multi_error: 0.325605\n",
      "[1392]\tvalid_0's multi_error: 0.325538\n",
      "[1393]\tvalid_0's multi_error: 0.325405\n",
      "[1394]\tvalid_0's multi_error: 0.325361\n",
      "[1395]\tvalid_0's multi_error: 0.325427\n",
      "[1396]\tvalid_0's multi_error: 0.325627\n",
      "[1397]\tvalid_0's multi_error: 0.325538\n",
      "[1398]\tvalid_0's multi_error: 0.325538\n",
      "[1399]\tvalid_0's multi_error: 0.325383\n",
      "[1400]\tvalid_0's multi_error: 0.32545\n",
      "[1401]\tvalid_0's multi_error: 0.325227\n",
      "[1402]\tvalid_0's multi_error: 0.325183\n",
      "[1403]\tvalid_0's multi_error: 0.325183\n",
      "[1404]\tvalid_0's multi_error: 0.32525\n",
      "[1405]\tvalid_0's multi_error: 0.32525\n",
      "[1406]\tvalid_0's multi_error: 0.325294\n",
      "[1407]\tvalid_0's multi_error: 0.325294\n",
      "[1408]\tvalid_0's multi_error: 0.32525\n",
      "[1409]\tvalid_0's multi_error: 0.32525\n",
      "[1410]\tvalid_0's multi_error: 0.325294\n",
      "[1411]\tvalid_0's multi_error: 0.325205\n",
      "[1412]\tvalid_0's multi_error: 0.325116\n",
      "[1413]\tvalid_0's multi_error: 0.325161\n",
      "[1414]\tvalid_0's multi_error: 0.325116\n",
      "[1415]\tvalid_0's multi_error: 0.325227\n",
      "[1416]\tvalid_0's multi_error: 0.325338\n",
      "[1417]\tvalid_0's multi_error: 0.325161\n",
      "[1418]\tvalid_0's multi_error: 0.325027\n",
      "[1419]\tvalid_0's multi_error: 0.324916\n",
      "[1420]\tvalid_0's multi_error: 0.324916\n",
      "[1421]\tvalid_0's multi_error: 0.324872\n",
      "[1422]\tvalid_0's multi_error: 0.325094\n",
      "[1423]\tvalid_0's multi_error: 0.325138\n",
      "[1424]\tvalid_0's multi_error: 0.325161\n",
      "[1425]\tvalid_0's multi_error: 0.325049\n",
      "[1426]\tvalid_0's multi_error: 0.324961\n",
      "[1427]\tvalid_0's multi_error: 0.324872\n",
      "[1428]\tvalid_0's multi_error: 0.324849\n",
      "[1429]\tvalid_0's multi_error: 0.324894\n",
      "[1430]\tvalid_0's multi_error: 0.324872\n",
      "[1431]\tvalid_0's multi_error: 0.324894\n",
      "[1432]\tvalid_0's multi_error: 0.324738\n",
      "[1433]\tvalid_0's multi_error: 0.324916\n",
      "[1434]\tvalid_0's multi_error: 0.324983\n",
      "[1435]\tvalid_0's multi_error: 0.325005\n",
      "[1436]\tvalid_0's multi_error: 0.324894\n",
      "[1437]\tvalid_0's multi_error: 0.324894\n",
      "[1438]\tvalid_0's multi_error: 0.324694\n",
      "[1439]\tvalid_0's multi_error: 0.324938\n",
      "[1440]\tvalid_0's multi_error: 0.324983\n",
      "[1441]\tvalid_0's multi_error: 0.325094\n",
      "[1442]\tvalid_0's multi_error: 0.325027\n",
      "[1443]\tvalid_0's multi_error: 0.325094\n",
      "[1444]\tvalid_0's multi_error: 0.325049\n",
      "[1445]\tvalid_0's multi_error: 0.325161\n",
      "[1446]\tvalid_0's multi_error: 0.325049\n",
      "[1447]\tvalid_0's multi_error: 0.324983\n",
      "[1448]\tvalid_0's multi_error: 0.325005\n",
      "[1449]\tvalid_0's multi_error: 0.324983\n",
      "[1450]\tvalid_0's multi_error: 0.324983\n",
      "[1451]\tvalid_0's multi_error: 0.324916\n",
      "[1452]\tvalid_0's multi_error: 0.324961\n",
      "[1453]\tvalid_0's multi_error: 0.325072\n",
      "[1454]\tvalid_0's multi_error: 0.325138\n",
      "[1455]\tvalid_0's multi_error: 0.325116\n",
      "[1456]\tvalid_0's multi_error: 0.324961\n",
      "[1457]\tvalid_0's multi_error: 0.325094\n",
      "[1458]\tvalid_0's multi_error: 0.325072\n",
      "[1459]\tvalid_0's multi_error: 0.325094\n",
      "[1460]\tvalid_0's multi_error: 0.325183\n",
      "[1461]\tvalid_0's multi_error: 0.325161\n",
      "[1462]\tvalid_0's multi_error: 0.325272\n",
      "[1463]\tvalid_0's multi_error: 0.325294\n",
      "[1464]\tvalid_0's multi_error: 0.325272\n",
      "[1465]\tvalid_0's multi_error: 0.325205\n",
      "[1466]\tvalid_0's multi_error: 0.325205\n",
      "[1467]\tvalid_0's multi_error: 0.325227\n",
      "[1468]\tvalid_0's multi_error: 0.325227\n",
      "[1469]\tvalid_0's multi_error: 0.325227\n",
      "[1470]\tvalid_0's multi_error: 0.325161\n",
      "[1471]\tvalid_0's multi_error: 0.325338\n",
      "[1472]\tvalid_0's multi_error: 0.325316\n",
      "[1473]\tvalid_0's multi_error: 0.325272\n",
      "[1474]\tvalid_0's multi_error: 0.325294\n",
      "[1475]\tvalid_0's multi_error: 0.325183\n",
      "[1476]\tvalid_0's multi_error: 0.325205\n",
      "[1477]\tvalid_0's multi_error: 0.325138\n",
      "[1478]\tvalid_0's multi_error: 0.32525\n",
      "[1479]\tvalid_0's multi_error: 0.32525\n",
      "[1480]\tvalid_0's multi_error: 0.325161\n",
      "[1481]\tvalid_0's multi_error: 0.325205\n",
      "[1482]\tvalid_0's multi_error: 0.325072\n",
      "[1483]\tvalid_0's multi_error: 0.325072\n",
      "[1484]\tvalid_0's multi_error: 0.325049\n",
      "[1485]\tvalid_0's multi_error: 0.325027\n",
      "[1486]\tvalid_0's multi_error: 0.325116\n",
      "[1487]\tvalid_0's multi_error: 0.325161\n",
      "[1488]\tvalid_0's multi_error: 0.32525\n",
      "[1489]\tvalid_0's multi_error: 0.325138\n",
      "[1490]\tvalid_0's multi_error: 0.32525\n",
      "[1491]\tvalid_0's multi_error: 0.325138\n",
      "[1492]\tvalid_0's multi_error: 0.325027\n",
      "[1493]\tvalid_0's multi_error: 0.325138\n",
      "[1494]\tvalid_0's multi_error: 0.325094\n",
      "[1495]\tvalid_0's multi_error: 0.325005\n",
      "[1496]\tvalid_0's multi_error: 0.324894\n",
      "[1497]\tvalid_0's multi_error: 0.324938\n",
      "[1498]\tvalid_0's multi_error: 0.324783\n",
      "[1499]\tvalid_0's multi_error: 0.324783\n",
      "[1500]\tvalid_0's multi_error: 0.324849\n",
      "[1501]\tvalid_0's multi_error: 0.324849\n",
      "[1502]\tvalid_0's multi_error: 0.324738\n",
      "[1503]\tvalid_0's multi_error: 0.324738\n",
      "[1504]\tvalid_0's multi_error: 0.324738\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1505]\tvalid_0's multi_error: 0.324783\n",
      "[1506]\tvalid_0's multi_error: 0.324849\n",
      "[1507]\tvalid_0's multi_error: 0.324938\n",
      "[1508]\tvalid_0's multi_error: 0.324983\n",
      "[1509]\tvalid_0's multi_error: 0.325094\n",
      "[1510]\tvalid_0's multi_error: 0.325094\n",
      "[1511]\tvalid_0's multi_error: 0.324938\n",
      "[1512]\tvalid_0's multi_error: 0.324649\n",
      "[1513]\tvalid_0's multi_error: 0.324583\n",
      "[1514]\tvalid_0's multi_error: 0.324583\n",
      "[1515]\tvalid_0's multi_error: 0.324583\n",
      "[1516]\tvalid_0's multi_error: 0.324427\n",
      "[1517]\tvalid_0's multi_error: 0.324294\n",
      "[1518]\tvalid_0's multi_error: 0.324116\n",
      "[1519]\tvalid_0's multi_error: 0.324316\n",
      "[1520]\tvalid_0's multi_error: 0.324249\n",
      "[1521]\tvalid_0's multi_error: 0.324294\n",
      "[1522]\tvalid_0's multi_error: 0.324472\n",
      "[1523]\tvalid_0's multi_error: 0.324427\n",
      "[1524]\tvalid_0's multi_error: 0.324583\n",
      "[1525]\tvalid_0's multi_error: 0.32456\n",
      "[1526]\tvalid_0's multi_error: 0.324583\n",
      "[1527]\tvalid_0's multi_error: 0.324738\n",
      "[1528]\tvalid_0's multi_error: 0.324694\n",
      "[1529]\tvalid_0's multi_error: 0.324783\n",
      "[1530]\tvalid_0's multi_error: 0.324783\n",
      "[1531]\tvalid_0's multi_error: 0.324827\n",
      "[1532]\tvalid_0's multi_error: 0.324783\n",
      "[1533]\tvalid_0's multi_error: 0.324738\n",
      "[1534]\tvalid_0's multi_error: 0.324783\n",
      "[1535]\tvalid_0's multi_error: 0.324716\n",
      "[1536]\tvalid_0's multi_error: 0.324627\n",
      "[1537]\tvalid_0's multi_error: 0.32456\n",
      "[1538]\tvalid_0's multi_error: 0.324472\n",
      "[1539]\tvalid_0's multi_error: 0.324383\n",
      "[1540]\tvalid_0's multi_error: 0.324472\n",
      "[1541]\tvalid_0's multi_error: 0.324472\n",
      "[1542]\tvalid_0's multi_error: 0.324605\n",
      "[1543]\tvalid_0's multi_error: 0.324694\n",
      "[1544]\tvalid_0's multi_error: 0.324716\n",
      "[1545]\tvalid_0's multi_error: 0.324649\n",
      "[1546]\tvalid_0's multi_error: 0.324583\n",
      "[1547]\tvalid_0's multi_error: 0.324627\n",
      "[1548]\tvalid_0's multi_error: 0.324538\n",
      "[1549]\tvalid_0's multi_error: 0.324672\n",
      "[1550]\tvalid_0's multi_error: 0.324716\n",
      "[1551]\tvalid_0's multi_error: 0.324672\n",
      "[1552]\tvalid_0's multi_error: 0.324849\n",
      "[1553]\tvalid_0's multi_error: 0.324649\n",
      "[1554]\tvalid_0's multi_error: 0.32456\n",
      "[1555]\tvalid_0's multi_error: 0.324583\n",
      "[1556]\tvalid_0's multi_error: 0.324672\n",
      "[1557]\tvalid_0's multi_error: 0.324694\n",
      "[1558]\tvalid_0's multi_error: 0.32476\n",
      "[1559]\tvalid_0's multi_error: 0.324738\n",
      "[1560]\tvalid_0's multi_error: 0.324805\n",
      "[1561]\tvalid_0's multi_error: 0.324716\n",
      "[1562]\tvalid_0's multi_error: 0.324627\n",
      "[1563]\tvalid_0's multi_error: 0.324694\n",
      "[1564]\tvalid_0's multi_error: 0.324583\n",
      "[1565]\tvalid_0's multi_error: 0.324672\n",
      "[1566]\tvalid_0's multi_error: 0.324494\n",
      "[1567]\tvalid_0's multi_error: 0.324627\n",
      "[1568]\tvalid_0's multi_error: 0.324649\n",
      "[1569]\tvalid_0's multi_error: 0.324805\n",
      "[1570]\tvalid_0's multi_error: 0.324805\n",
      "[1571]\tvalid_0's multi_error: 0.324961\n",
      "[1572]\tvalid_0's multi_error: 0.324916\n",
      "[1573]\tvalid_0's multi_error: 0.324849\n",
      "[1574]\tvalid_0's multi_error: 0.324716\n",
      "[1575]\tvalid_0's multi_error: 0.324805\n",
      "[1576]\tvalid_0's multi_error: 0.324716\n",
      "[1577]\tvalid_0's multi_error: 0.324494\n",
      "[1578]\tvalid_0's multi_error: 0.324605\n",
      "[1579]\tvalid_0's multi_error: 0.324605\n",
      "[1580]\tvalid_0's multi_error: 0.324649\n",
      "[1581]\tvalid_0's multi_error: 0.324516\n",
      "[1582]\tvalid_0's multi_error: 0.324494\n",
      "[1583]\tvalid_0's multi_error: 0.32456\n",
      "[1584]\tvalid_0's multi_error: 0.324605\n",
      "[1585]\tvalid_0's multi_error: 0.324516\n",
      "[1586]\tvalid_0's multi_error: 0.324338\n",
      "[1587]\tvalid_0's multi_error: 0.324271\n",
      "[1588]\tvalid_0's multi_error: 0.324316\n",
      "[1589]\tvalid_0's multi_error: 0.324449\n",
      "[1590]\tvalid_0's multi_error: 0.324494\n",
      "[1591]\tvalid_0's multi_error: 0.324494\n",
      "[1592]\tvalid_0's multi_error: 0.324672\n",
      "[1593]\tvalid_0's multi_error: 0.32456\n",
      "[1594]\tvalid_0's multi_error: 0.32436\n",
      "[1595]\tvalid_0's multi_error: 0.324449\n",
      "[1596]\tvalid_0's multi_error: 0.324583\n",
      "[1597]\tvalid_0's multi_error: 0.324449\n",
      "[1598]\tvalid_0's multi_error: 0.324627\n",
      "[1599]\tvalid_0's multi_error: 0.324672\n",
      "[1600]\tvalid_0's multi_error: 0.32476\n",
      "[1601]\tvalid_0's multi_error: 0.324805\n",
      "[1602]\tvalid_0's multi_error: 0.324849\n",
      "[1603]\tvalid_0's multi_error: 0.324849\n",
      "[1604]\tvalid_0's multi_error: 0.324961\n",
      "[1605]\tvalid_0's multi_error: 0.324916\n",
      "[1606]\tvalid_0's multi_error: 0.325005\n",
      "[1607]\tvalid_0's multi_error: 0.324872\n",
      "[1608]\tvalid_0's multi_error: 0.324849\n",
      "[1609]\tvalid_0's multi_error: 0.324738\n",
      "[1610]\tvalid_0's multi_error: 0.324649\n",
      "[1611]\tvalid_0's multi_error: 0.32476\n",
      "[1612]\tvalid_0's multi_error: 0.324738\n",
      "[1613]\tvalid_0's multi_error: 0.324716\n",
      "[1614]\tvalid_0's multi_error: 0.32456\n",
      "[1615]\tvalid_0's multi_error: 0.324805\n",
      "[1616]\tvalid_0's multi_error: 0.324783\n",
      "[1617]\tvalid_0's multi_error: 0.324738\n",
      "[1618]\tvalid_0's multi_error: 0.324649\n",
      "[1619]\tvalid_0's multi_error: 0.32456\n",
      "[1620]\tvalid_0's multi_error: 0.324716\n",
      "[1621]\tvalid_0's multi_error: 0.324827\n",
      "[1622]\tvalid_0's multi_error: 0.324805\n",
      "[1623]\tvalid_0's multi_error: 0.324916\n",
      "[1624]\tvalid_0's multi_error: 0.324894\n",
      "[1625]\tvalid_0's multi_error: 0.324938\n",
      "[1626]\tvalid_0's multi_error: 0.324916\n",
      "[1627]\tvalid_0's multi_error: 0.32476\n",
      "[1628]\tvalid_0's multi_error: 0.324627\n",
      "[1629]\tvalid_0's multi_error: 0.324583\n",
      "[1630]\tvalid_0's multi_error: 0.324494\n",
      "[1631]\tvalid_0's multi_error: 0.324672\n",
      "[1632]\tvalid_0's multi_error: 0.324649\n",
      "[1633]\tvalid_0's multi_error: 0.324516\n",
      "[1634]\tvalid_0's multi_error: 0.324605\n",
      "[1635]\tvalid_0's multi_error: 0.32456\n",
      "[1636]\tvalid_0's multi_error: 0.324672\n",
      "[1637]\tvalid_0's multi_error: 0.324516\n",
      "[1638]\tvalid_0's multi_error: 0.324538\n",
      "[1639]\tvalid_0's multi_error: 0.324583\n",
      "[1640]\tvalid_0's multi_error: 0.324494\n",
      "[1641]\tvalid_0's multi_error: 0.324405\n",
      "[1642]\tvalid_0's multi_error: 0.324449\n",
      "[1643]\tvalid_0's multi_error: 0.324405\n",
      "[1644]\tvalid_0's multi_error: 0.324494\n",
      "[1645]\tvalid_0's multi_error: 0.324405\n",
      "[1646]\tvalid_0's multi_error: 0.324383\n",
      "[1647]\tvalid_0's multi_error: 0.324449\n",
      "[1648]\tvalid_0's multi_error: 0.324672\n",
      "[1649]\tvalid_0's multi_error: 0.324672\n",
      "[1650]\tvalid_0's multi_error: 0.324516\n",
      "[1651]\tvalid_0's multi_error: 0.324649\n",
      "[1652]\tvalid_0's multi_error: 0.324694\n",
      "[1653]\tvalid_0's multi_error: 0.324783\n",
      "[1654]\tvalid_0's multi_error: 0.324672\n",
      "[1655]\tvalid_0's multi_error: 0.324672\n",
      "[1656]\tvalid_0's multi_error: 0.32476\n",
      "[1657]\tvalid_0's multi_error: 0.324961\n",
      "[1658]\tvalid_0's multi_error: 0.324916\n",
      "[1659]\tvalid_0's multi_error: 0.325005\n",
      "[1660]\tvalid_0's multi_error: 0.325005\n",
      "[1661]\tvalid_0's multi_error: 0.324938\n",
      "[1662]\tvalid_0's multi_error: 0.324983\n",
      "[1663]\tvalid_0's multi_error: 0.324983\n",
      "[1664]\tvalid_0's multi_error: 0.325049\n",
      "[1665]\tvalid_0's multi_error: 0.325272\n",
      "[1666]\tvalid_0's multi_error: 0.325116\n",
      "[1667]\tvalid_0's multi_error: 0.325183\n",
      "[1668]\tvalid_0's multi_error: 0.325138\n",
      "[1669]\tvalid_0's multi_error: 0.325094\n",
      "[1670]\tvalid_0's multi_error: 0.325049\n",
      "[1671]\tvalid_0's multi_error: 0.325227\n",
      "[1672]\tvalid_0's multi_error: 0.325116\n",
      "[1673]\tvalid_0's multi_error: 0.324961\n",
      "[1674]\tvalid_0's multi_error: 0.324916\n",
      "[1675]\tvalid_0's multi_error: 0.324983\n",
      "[1676]\tvalid_0's multi_error: 0.325049\n",
      "[1677]\tvalid_0's multi_error: 0.324983\n",
      "[1678]\tvalid_0's multi_error: 0.325161\n",
      "[1679]\tvalid_0's multi_error: 0.325049\n",
      "[1680]\tvalid_0's multi_error: 0.324983\n",
      "[1681]\tvalid_0's multi_error: 0.324894\n",
      "[1682]\tvalid_0's multi_error: 0.324805\n",
      "[1683]\tvalid_0's multi_error: 0.324849\n",
      "[1684]\tvalid_0's multi_error: 0.324938\n",
      "[1685]\tvalid_0's multi_error: 0.324849\n",
      "[1686]\tvalid_0's multi_error: 0.324938\n",
      "[1687]\tvalid_0's multi_error: 0.325072\n",
      "[1688]\tvalid_0's multi_error: 0.325116\n",
      "[1689]\tvalid_0's multi_error: 0.325049\n",
      "[1690]\tvalid_0's multi_error: 0.325094\n",
      "[1691]\tvalid_0's multi_error: 0.325049\n",
      "[1692]\tvalid_0's multi_error: 0.324983\n",
      "[1693]\tvalid_0's multi_error: 0.324938\n",
      "[1694]\tvalid_0's multi_error: 0.324783\n",
      "[1695]\tvalid_0's multi_error: 0.324849\n",
      "[1696]\tvalid_0's multi_error: 0.324716\n",
      "[1697]\tvalid_0's multi_error: 0.324605\n",
      "[1698]\tvalid_0's multi_error: 0.324605\n",
      "[1699]\tvalid_0's multi_error: 0.324605\n",
      "[1700]\tvalid_0's multi_error: 0.324494\n",
      "[1701]\tvalid_0's multi_error: 0.32456\n",
      "[1702]\tvalid_0's multi_error: 0.324494\n",
      "[1703]\tvalid_0's multi_error: 0.324516\n",
      "[1704]\tvalid_0's multi_error: 0.324538\n",
      "[1705]\tvalid_0's multi_error: 0.324538\n",
      "[1706]\tvalid_0's multi_error: 0.324649\n",
      "[1707]\tvalid_0's multi_error: 0.324783\n",
      "[1708]\tvalid_0's multi_error: 0.324627\n",
      "[1709]\tvalid_0's multi_error: 0.324472\n",
      "[1710]\tvalid_0's multi_error: 0.324516\n",
      "[1711]\tvalid_0's multi_error: 0.324516\n",
      "[1712]\tvalid_0's multi_error: 0.324516\n",
      "[1713]\tvalid_0's multi_error: 0.324605\n",
      "[1714]\tvalid_0's multi_error: 0.324672\n",
      "[1715]\tvalid_0's multi_error: 0.324783\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1716]\tvalid_0's multi_error: 0.324538\n",
      "[1717]\tvalid_0's multi_error: 0.324338\n",
      "[1718]\tvalid_0's multi_error: 0.324227\n",
      "[1719]\tvalid_0's multi_error: 0.32436\n",
      "[1720]\tvalid_0's multi_error: 0.324383\n",
      "[1721]\tvalid_0's multi_error: 0.324427\n",
      "[1722]\tvalid_0's multi_error: 0.324383\n",
      "[1723]\tvalid_0's multi_error: 0.32436\n",
      "[1724]\tvalid_0's multi_error: 0.324383\n",
      "[1725]\tvalid_0's multi_error: 0.324338\n",
      "[1726]\tvalid_0's multi_error: 0.324449\n",
      "[1727]\tvalid_0's multi_error: 0.324494\n",
      "[1728]\tvalid_0's multi_error: 0.324449\n",
      "[1729]\tvalid_0's multi_error: 0.324383\n",
      "[1730]\tvalid_0's multi_error: 0.324271\n",
      "[1731]\tvalid_0's multi_error: 0.32436\n",
      "[1732]\tvalid_0's multi_error: 0.32436\n",
      "[1733]\tvalid_0's multi_error: 0.324294\n",
      "[1734]\tvalid_0's multi_error: 0.324338\n",
      "[1735]\tvalid_0's multi_error: 0.32436\n",
      "[1736]\tvalid_0's multi_error: 0.324672\n",
      "[1737]\tvalid_0's multi_error: 0.324783\n",
      "[1738]\tvalid_0's multi_error: 0.324649\n",
      "[1739]\tvalid_0's multi_error: 0.324716\n",
      "[1740]\tvalid_0's multi_error: 0.32476\n",
      "[1741]\tvalid_0's multi_error: 0.324827\n",
      "[1742]\tvalid_0's multi_error: 0.324894\n",
      "[1743]\tvalid_0's multi_error: 0.324894\n",
      "[1744]\tvalid_0's multi_error: 0.324872\n",
      "[1745]\tvalid_0's multi_error: 0.324849\n",
      "[1746]\tvalid_0's multi_error: 0.324827\n",
      "[1747]\tvalid_0's multi_error: 0.324983\n",
      "[1748]\tvalid_0's multi_error: 0.324894\n",
      "[1749]\tvalid_0's multi_error: 0.324849\n",
      "[1750]\tvalid_0's multi_error: 0.32476\n",
      "[1751]\tvalid_0's multi_error: 0.324605\n",
      "[1752]\tvalid_0's multi_error: 0.324516\n",
      "[1753]\tvalid_0's multi_error: 0.324494\n",
      "[1754]\tvalid_0's multi_error: 0.324538\n",
      "[1755]\tvalid_0's multi_error: 0.324649\n",
      "[1756]\tvalid_0's multi_error: 0.324694\n",
      "[1757]\tvalid_0's multi_error: 0.324649\n",
      "[1758]\tvalid_0's multi_error: 0.324849\n",
      "[1759]\tvalid_0's multi_error: 0.324916\n",
      "[1760]\tvalid_0's multi_error: 0.324983\n",
      "[1761]\tvalid_0's multi_error: 0.325005\n",
      "[1762]\tvalid_0's multi_error: 0.324961\n",
      "[1763]\tvalid_0's multi_error: 0.325027\n",
      "[1764]\tvalid_0's multi_error: 0.325294\n",
      "[1765]\tvalid_0's multi_error: 0.325138\n",
      "[1766]\tvalid_0's multi_error: 0.325116\n",
      "[1767]\tvalid_0's multi_error: 0.325005\n",
      "[1768]\tvalid_0's multi_error: 0.324894\n",
      "[1769]\tvalid_0's multi_error: 0.324938\n",
      "[1770]\tvalid_0's multi_error: 0.325116\n",
      "[1771]\tvalid_0's multi_error: 0.325138\n",
      "[1772]\tvalid_0's multi_error: 0.325338\n",
      "[1773]\tvalid_0's multi_error: 0.325338\n",
      "[1774]\tvalid_0's multi_error: 0.325294\n",
      "[1775]\tvalid_0's multi_error: 0.325183\n",
      "[1776]\tvalid_0's multi_error: 0.325316\n",
      "[1777]\tvalid_0's multi_error: 0.325316\n",
      "[1778]\tvalid_0's multi_error: 0.325227\n",
      "[1779]\tvalid_0's multi_error: 0.325338\n",
      "[1780]\tvalid_0's multi_error: 0.32525\n",
      "[1781]\tvalid_0's multi_error: 0.325072\n",
      "[1782]\tvalid_0's multi_error: 0.325005\n",
      "[1783]\tvalid_0's multi_error: 0.324916\n",
      "[1784]\tvalid_0's multi_error: 0.325005\n",
      "[1785]\tvalid_0's multi_error: 0.325049\n",
      "[1786]\tvalid_0's multi_error: 0.325027\n",
      "[1787]\tvalid_0's multi_error: 0.325094\n",
      "[1788]\tvalid_0's multi_error: 0.325072\n",
      "[1789]\tvalid_0's multi_error: 0.324916\n",
      "[1790]\tvalid_0's multi_error: 0.325049\n",
      "[1791]\tvalid_0's multi_error: 0.325027\n",
      "[1792]\tvalid_0's multi_error: 0.325027\n",
      "[1793]\tvalid_0's multi_error: 0.325027\n",
      "[1794]\tvalid_0's multi_error: 0.325072\n",
      "[1795]\tvalid_0's multi_error: 0.325183\n",
      "[1796]\tvalid_0's multi_error: 0.325361\n",
      "[1797]\tvalid_0's multi_error: 0.325183\n",
      "[1798]\tvalid_0's multi_error: 0.325227\n",
      "[1799]\tvalid_0's multi_error: 0.325138\n",
      "[1800]\tvalid_0's multi_error: 0.325049\n",
      "[1801]\tvalid_0's multi_error: 0.324983\n",
      "[1802]\tvalid_0's multi_error: 0.324938\n",
      "[1803]\tvalid_0's multi_error: 0.324894\n",
      "[1804]\tvalid_0's multi_error: 0.324983\n",
      "[1805]\tvalid_0's multi_error: 0.325094\n",
      "[1806]\tvalid_0's multi_error: 0.324961\n",
      "[1807]\tvalid_0's multi_error: 0.325027\n",
      "[1808]\tvalid_0's multi_error: 0.325094\n",
      "[1809]\tvalid_0's multi_error: 0.325072\n",
      "[1810]\tvalid_0's multi_error: 0.324961\n",
      "[1811]\tvalid_0's multi_error: 0.324894\n",
      "[1812]\tvalid_0's multi_error: 0.324738\n",
      "[1813]\tvalid_0's multi_error: 0.324783\n",
      "[1814]\tvalid_0's multi_error: 0.324694\n",
      "[1815]\tvalid_0's multi_error: 0.324849\n",
      "[1816]\tvalid_0's multi_error: 0.324694\n",
      "[1817]\tvalid_0's multi_error: 0.32476\n",
      "[1818]\tvalid_0's multi_error: 0.324738\n",
      "[1819]\tvalid_0's multi_error: 0.324738\n",
      "[1820]\tvalid_0's multi_error: 0.324849\n",
      "[1821]\tvalid_0's multi_error: 0.32476\n",
      "[1822]\tvalid_0's multi_error: 0.32476\n",
      "[1823]\tvalid_0's multi_error: 0.324627\n",
      "[1824]\tvalid_0's multi_error: 0.324716\n",
      "[1825]\tvalid_0's multi_error: 0.324738\n",
      "[1826]\tvalid_0's multi_error: 0.324716\n",
      "[1827]\tvalid_0's multi_error: 0.32476\n",
      "[1828]\tvalid_0's multi_error: 0.32476\n",
      "[1829]\tvalid_0's multi_error: 0.324827\n",
      "[1830]\tvalid_0's multi_error: 0.324783\n",
      "[1831]\tvalid_0's multi_error: 0.324872\n",
      "[1832]\tvalid_0's multi_error: 0.324961\n",
      "[1833]\tvalid_0's multi_error: 0.324983\n",
      "[1834]\tvalid_0's multi_error: 0.324849\n",
      "[1835]\tvalid_0's multi_error: 0.324827\n",
      "[1836]\tvalid_0's multi_error: 0.324872\n",
      "[1837]\tvalid_0's multi_error: 0.324605\n",
      "[1838]\tvalid_0's multi_error: 0.324694\n",
      "[1839]\tvalid_0's multi_error: 0.324672\n",
      "[1840]\tvalid_0's multi_error: 0.324627\n",
      "[1841]\tvalid_0's multi_error: 0.324672\n",
      "[1842]\tvalid_0's multi_error: 0.324627\n",
      "[1843]\tvalid_0's multi_error: 0.324783\n",
      "[1844]\tvalid_0's multi_error: 0.324827\n",
      "[1845]\tvalid_0's multi_error: 0.324694\n",
      "[1846]\tvalid_0's multi_error: 0.324738\n",
      "[1847]\tvalid_0's multi_error: 0.324872\n",
      "[1848]\tvalid_0's multi_error: 0.324916\n",
      "[1849]\tvalid_0's multi_error: 0.325027\n",
      "[1850]\tvalid_0's multi_error: 0.325027\n",
      "[1851]\tvalid_0's multi_error: 0.325072\n",
      "[1852]\tvalid_0's multi_error: 0.324983\n",
      "[1853]\tvalid_0's multi_error: 0.324983\n",
      "[1854]\tvalid_0's multi_error: 0.325027\n",
      "[1855]\tvalid_0's multi_error: 0.324961\n",
      "[1856]\tvalid_0's multi_error: 0.325072\n",
      "[1857]\tvalid_0's multi_error: 0.324961\n",
      "[1858]\tvalid_0's multi_error: 0.325227\n",
      "[1859]\tvalid_0's multi_error: 0.325316\n",
      "[1860]\tvalid_0's multi_error: 0.325227\n",
      "[1861]\tvalid_0's multi_error: 0.325183\n",
      "[1862]\tvalid_0's multi_error: 0.325161\n",
      "[1863]\tvalid_0's multi_error: 0.325072\n",
      "[1864]\tvalid_0's multi_error: 0.325205\n",
      "[1865]\tvalid_0's multi_error: 0.325205\n",
      "[1866]\tvalid_0's multi_error: 0.325094\n",
      "[1867]\tvalid_0's multi_error: 0.325161\n",
      "[1868]\tvalid_0's multi_error: 0.32525\n",
      "[1869]\tvalid_0's multi_error: 0.325227\n",
      "[1870]\tvalid_0's multi_error: 0.325361\n",
      "[1871]\tvalid_0's multi_error: 0.325138\n",
      "[1872]\tvalid_0's multi_error: 0.325116\n",
      "[1873]\tvalid_0's multi_error: 0.325183\n",
      "[1874]\tvalid_0's multi_error: 0.32525\n",
      "[1875]\tvalid_0's multi_error: 0.325272\n",
      "[1876]\tvalid_0's multi_error: 0.32525\n",
      "[1877]\tvalid_0's multi_error: 0.325205\n",
      "[1878]\tvalid_0's multi_error: 0.325094\n",
      "[1879]\tvalid_0's multi_error: 0.325294\n",
      "[1880]\tvalid_0's multi_error: 0.325227\n",
      "[1881]\tvalid_0's multi_error: 0.325138\n",
      "[1882]\tvalid_0's multi_error: 0.325049\n",
      "[1883]\tvalid_0's multi_error: 0.325161\n",
      "[1884]\tvalid_0's multi_error: 0.325183\n",
      "[1885]\tvalid_0's multi_error: 0.325094\n",
      "[1886]\tvalid_0's multi_error: 0.325205\n",
      "[1887]\tvalid_0's multi_error: 0.325316\n",
      "[1888]\tvalid_0's multi_error: 0.325116\n",
      "[1889]\tvalid_0's multi_error: 0.325138\n",
      "[1890]\tvalid_0's multi_error: 0.324983\n",
      "[1891]\tvalid_0's multi_error: 0.324872\n",
      "[1892]\tvalid_0's multi_error: 0.32476\n",
      "[1893]\tvalid_0's multi_error: 0.324716\n",
      "[1894]\tvalid_0's multi_error: 0.324805\n",
      "[1895]\tvalid_0's multi_error: 0.32476\n",
      "[1896]\tvalid_0's multi_error: 0.324849\n",
      "[1897]\tvalid_0's multi_error: 0.324738\n",
      "[1898]\tvalid_0's multi_error: 0.32476\n",
      "[1899]\tvalid_0's multi_error: 0.324805\n",
      "[1900]\tvalid_0's multi_error: 0.324849\n",
      "[1901]\tvalid_0's multi_error: 0.324849\n",
      "[1902]\tvalid_0's multi_error: 0.324961\n",
      "[1903]\tvalid_0's multi_error: 0.324938\n",
      "[1904]\tvalid_0's multi_error: 0.324805\n",
      "[1905]\tvalid_0's multi_error: 0.324738\n",
      "[1906]\tvalid_0's multi_error: 0.324716\n",
      "[1907]\tvalid_0's multi_error: 0.324849\n",
      "[1908]\tvalid_0's multi_error: 0.324827\n",
      "[1909]\tvalid_0's multi_error: 0.324716\n",
      "[1910]\tvalid_0's multi_error: 0.324783\n",
      "[1911]\tvalid_0's multi_error: 0.324716\n",
      "[1912]\tvalid_0's multi_error: 0.32476\n",
      "[1913]\tvalid_0's multi_error: 0.32476\n",
      "[1914]\tvalid_0's multi_error: 0.324805\n",
      "[1915]\tvalid_0's multi_error: 0.324783\n",
      "[1916]\tvalid_0's multi_error: 0.324849\n",
      "[1917]\tvalid_0's multi_error: 0.324738\n",
      "[1918]\tvalid_0's multi_error: 0.324916\n",
      "[1919]\tvalid_0's multi_error: 0.324916\n",
      "[1920]\tvalid_0's multi_error: 0.324983\n",
      "[1921]\tvalid_0's multi_error: 0.324849\n",
      "[1922]\tvalid_0's multi_error: 0.324783\n",
      "[1923]\tvalid_0's multi_error: 0.32476\n",
      "[1924]\tvalid_0's multi_error: 0.324849\n",
      "[1925]\tvalid_0's multi_error: 0.324694\n",
      "[1926]\tvalid_0's multi_error: 0.324605\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1927]\tvalid_0's multi_error: 0.324827\n",
      "[1928]\tvalid_0's multi_error: 0.324894\n",
      "[1929]\tvalid_0's multi_error: 0.324872\n",
      "[1930]\tvalid_0's multi_error: 0.324849\n",
      "[1931]\tvalid_0's multi_error: 0.324872\n",
      "[1932]\tvalid_0's multi_error: 0.324894\n",
      "[1933]\tvalid_0's multi_error: 0.324827\n",
      "[1934]\tvalid_0's multi_error: 0.324805\n",
      "[1935]\tvalid_0's multi_error: 0.324872\n",
      "[1936]\tvalid_0's multi_error: 0.324672\n",
      "[1937]\tvalid_0's multi_error: 0.324649\n",
      "[1938]\tvalid_0's multi_error: 0.324694\n",
      "[1939]\tvalid_0's multi_error: 0.324672\n",
      "[1940]\tvalid_0's multi_error: 0.324694\n",
      "[1941]\tvalid_0's multi_error: 0.324672\n",
      "[1942]\tvalid_0's multi_error: 0.324605\n",
      "[1943]\tvalid_0's multi_error: 0.324672\n",
      "[1944]\tvalid_0's multi_error: 0.324694\n",
      "[1945]\tvalid_0's multi_error: 0.324649\n",
      "[1946]\tvalid_0's multi_error: 0.324583\n",
      "[1947]\tvalid_0's multi_error: 0.324649\n",
      "[1948]\tvalid_0's multi_error: 0.324672\n",
      "[1949]\tvalid_0's multi_error: 0.324738\n",
      "[1950]\tvalid_0's multi_error: 0.324672\n",
      "[1951]\tvalid_0's multi_error: 0.324672\n",
      "[1952]\tvalid_0's multi_error: 0.32456\n",
      "[1953]\tvalid_0's multi_error: 0.324627\n",
      "[1954]\tvalid_0's multi_error: 0.324516\n",
      "[1955]\tvalid_0's multi_error: 0.324672\n",
      "[1956]\tvalid_0's multi_error: 0.324649\n",
      "[1957]\tvalid_0's multi_error: 0.324672\n",
      "[1958]\tvalid_0's multi_error: 0.32476\n",
      "[1959]\tvalid_0's multi_error: 0.324805\n",
      "[1960]\tvalid_0's multi_error: 0.32476\n",
      "[1961]\tvalid_0's multi_error: 0.324827\n",
      "[1962]\tvalid_0's multi_error: 0.324783\n",
      "[1963]\tvalid_0's multi_error: 0.324827\n",
      "[1964]\tvalid_0's multi_error: 0.324849\n",
      "[1965]\tvalid_0's multi_error: 0.324849\n",
      "[1966]\tvalid_0's multi_error: 0.324894\n",
      "[1967]\tvalid_0's multi_error: 0.324805\n",
      "[1968]\tvalid_0's multi_error: 0.324805\n",
      "[1969]\tvalid_0's multi_error: 0.324827\n",
      "[1970]\tvalid_0's multi_error: 0.324738\n",
      "[1971]\tvalid_0's multi_error: 0.324738\n",
      "[1972]\tvalid_0's multi_error: 0.324649\n",
      "[1973]\tvalid_0's multi_error: 0.324672\n",
      "[1974]\tvalid_0's multi_error: 0.32476\n",
      "[1975]\tvalid_0's multi_error: 0.324827\n",
      "[1976]\tvalid_0's multi_error: 0.32476\n",
      "[1977]\tvalid_0's multi_error: 0.324849\n",
      "[1978]\tvalid_0's multi_error: 0.324849\n",
      "[1979]\tvalid_0's multi_error: 0.324872\n",
      "[1980]\tvalid_0's multi_error: 0.324894\n",
      "[1981]\tvalid_0's multi_error: 0.324961\n",
      "[1982]\tvalid_0's multi_error: 0.324849\n",
      "[1983]\tvalid_0's multi_error: 0.324827\n",
      "[1984]\tvalid_0's multi_error: 0.324783\n",
      "[1985]\tvalid_0's multi_error: 0.324805\n",
      "[1986]\tvalid_0's multi_error: 0.324649\n",
      "[1987]\tvalid_0's multi_error: 0.324649\n",
      "[1988]\tvalid_0's multi_error: 0.324694\n",
      "[1989]\tvalid_0's multi_error: 0.324738\n",
      "[1990]\tvalid_0's multi_error: 0.324716\n",
      "[1991]\tvalid_0's multi_error: 0.324783\n",
      "[1992]\tvalid_0's multi_error: 0.324783\n",
      "[1993]\tvalid_0's multi_error: 0.32476\n",
      "[1994]\tvalid_0's multi_error: 0.324738\n",
      "[1995]\tvalid_0's multi_error: 0.324827\n",
      "[1996]\tvalid_0's multi_error: 0.324916\n",
      "[1997]\tvalid_0's multi_error: 0.32476\n",
      "[1998]\tvalid_0's multi_error: 0.324783\n",
      "[1999]\tvalid_0's multi_error: 0.324738\n",
      "[2000]\tvalid_0's multi_error: 0.324605\n",
      "[2001]\tvalid_0's multi_error: 0.324827\n",
      "[2002]\tvalid_0's multi_error: 0.324961\n",
      "[2003]\tvalid_0's multi_error: 0.324916\n",
      "[2004]\tvalid_0's multi_error: 0.324916\n",
      "[2005]\tvalid_0's multi_error: 0.325027\n",
      "[2006]\tvalid_0's multi_error: 0.324849\n",
      "[2007]\tvalid_0's multi_error: 0.324938\n",
      "[2008]\tvalid_0's multi_error: 0.324849\n",
      "[2009]\tvalid_0's multi_error: 0.324872\n",
      "[2010]\tvalid_0's multi_error: 0.324805\n",
      "[2011]\tvalid_0's multi_error: 0.324849\n",
      "[2012]\tvalid_0's multi_error: 0.324894\n",
      "[2013]\tvalid_0's multi_error: 0.324894\n",
      "[2014]\tvalid_0's multi_error: 0.324783\n",
      "[2015]\tvalid_0's multi_error: 0.324938\n",
      "[2016]\tvalid_0's multi_error: 0.324894\n",
      "[2017]\tvalid_0's multi_error: 0.324872\n",
      "[2018]\tvalid_0's multi_error: 0.324894\n",
      "Early stopping, best iteration is:\n",
      "[1518]\tvalid_0's multi_error: 0.324116\n"
     ]
    }
   ],
   "source": [
    "import lightgbm as lgb\n",
    "# create dataset for lightgbm  \n",
    "lgb_train = lgb.Dataset(train[:600000], y[:600000])  \n",
    "lgb_eval = lgb.Dataset(train[600000:], y[600000:], reference=lgb_train)  \n",
    "# specify your configurations as a dict  \n",
    "params = {  \n",
    "    'boosting_type': 'gbdt',  \n",
    "    'objective': 'multiclass',  \n",
    "    'num_class': 4,  \n",
    "    'metric': ['multi_error', 'map@2'],  # 'map@2', \n",
    "    'num_leaves': 250, # 4\n",
    "    'min_data_in_leaf': 100,\n",
    "    'learning_rate': 0.1,  \n",
    "#     'feature_fraction': 0.3,  \n",
    "    'bagging_fraction': 0.8,  \n",
    "    'bagging_freq': 5,  \n",
    "    'lambda_l1': 0.4,  \n",
    "    'lambda_l2': 0.6,\n",
    "    'max_depth':6,\n",
    "#     'min_gain_to_split': 0.2,  \n",
    "    'verbose': 5,  \n",
    "    'is_unbalance': True\n",
    "}  \n",
    "  \n",
    "print('Start training...')  \n",
    "gbm = lgb.train(params,  \n",
    "                lgb_train,  \n",
    "                num_boost_round=8000,  \n",
    "                valid_sets=lgb_eval,  \n",
    "                early_stopping_rounds=500)  \n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start predicting...\n",
      "0.796050152949\n"
     ]
    }
   ],
   "source": [
    "print('Start predicting...')\n",
    "pb = gbm.predict(train, num_iteration=gbm.best_iteration)\n",
    "pb = np.array(pb)\n",
    "submit = pd.DataFrame()\n",
    "submit['y1'] = pb.argsort()[np.arange(len(pb)), -1]\n",
    "submit['y2'] = pb.argsort()[np.arange(len(pb)), -2]\n",
    "print(test_score(submit['y1'].values, submit['y2'].values, y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pb = gbm.predict(test, num_iteration=gbm.best_iteration)\n",
    "pb = np.array(pb)\n",
    "lgb_submit = pd.DataFrame()\n",
    "lgb_submit['y1'] = pb.argsort()[np.arange(len(pb)), -1]\n",
    "lgb_submit['y2'] = pb.argsort()[np.arange(len(pb)), -2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lgb_submit.to_csv('lgb_submit.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/heolis/anaconda3/envs/tensorflow/lib/python3.5/site-packages/ipykernel_launcher.py:3: FutureWarning: reshape is deprecated and will raise in a subsequent release. Please use .values.reshape(...) instead\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "/home/heolis/anaconda3/envs/tensorflow/lib/python3.5/site-packages/ipykernel_launcher.py:4: FutureWarning: reshape is deprecated and will raise in a subsequent release. Please use .values.reshape(...) instead\n",
      "  after removing the cwd from sys.path.\n",
      "Using TensorFlow backend.\n",
      "/home/heolis/anaconda3/envs/tensorflow/lib/python3.5/site-packages/ipykernel_launcher.py:19: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(units=128, input_dim=38)`\n",
      "/home/heolis/anaconda3/envs/tensorflow/lib/python3.5/site-packages/ipykernel_launcher.py:21: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(units=256, input_dim=128)`\n",
      "/home/heolis/anaconda3/envs/tensorflow/lib/python3.5/site-packages/ipykernel_launcher.py:23: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(units=256, input_dim=256)`\n",
      "/home/heolis/anaconda3/envs/tensorflow/lib/python3.5/site-packages/ipykernel_launcher.py:26: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(units=512, input_dim=256)`\n",
      "/home/heolis/anaconda3/envs/tensorflow/lib/python3.5/site-packages/ipykernel_launcher.py:28: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(units=4, input_dim=512)`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 644987 samples, validate on 44987 samples\n",
      "Epoch 1/150\n",
      "644987/644987 [==============================] - 3s 5us/step - loss: 1.9309 - acc: 0.5842 - val_loss: 0.7911 - val_acc: 0.6194\n",
      "Epoch 2/150\n",
      "644987/644987 [==============================] - 2s 4us/step - loss: 0.7803 - acc: 0.6259 - val_loss: 0.7646 - val_acc: 0.6296\n",
      "Epoch 3/150\n",
      "644987/644987 [==============================] - 2s 4us/step - loss: 0.7697 - acc: 0.6298 - val_loss: 0.7565 - val_acc: 0.6330\n",
      "Epoch 4/150\n",
      "644987/644987 [==============================] - 2s 4us/step - loss: 0.7647 - acc: 0.6318 - val_loss: 0.7650 - val_acc: 0.6272\n",
      "Epoch 5/150\n",
      "644987/644987 [==============================] - 2s 4us/step - loss: 0.7630 - acc: 0.6324 - val_loss: 0.7562 - val_acc: 0.6338\n",
      "Epoch 6/150\n",
      "644987/644987 [==============================] - 2s 4us/step - loss: 0.7621 - acc: 0.6327 - val_loss: 0.7646 - val_acc: 0.6237\n",
      "Epoch 7/150\n",
      "644987/644987 [==============================] - 2s 4us/step - loss: 0.7615 - acc: 0.6329 - val_loss: 0.7632 - val_acc: 0.6274\n",
      "Epoch 8/150\n",
      "644987/644987 [==============================] - 2s 4us/step - loss: 0.7595 - acc: 0.6331 - val_loss: 0.7589 - val_acc: 0.6324\n",
      "Epoch 9/150\n",
      "644987/644987 [==============================] - 2s 4us/step - loss: 0.7576 - acc: 0.6345 - val_loss: 0.7757 - val_acc: 0.6237\n",
      "Epoch 10/150\n",
      "644987/644987 [==============================] - 2s 4us/step - loss: 0.7579 - acc: 0.6342 - val_loss: 0.7502 - val_acc: 0.6384\n",
      "Epoch 11/150\n",
      "644987/644987 [==============================] - 2s 4us/step - loss: 0.7550 - acc: 0.6358 - val_loss: 0.7509 - val_acc: 0.6385\n",
      "Epoch 12/150\n",
      "644987/644987 [==============================] - 2s 4us/step - loss: 0.7519 - acc: 0.6379 - val_loss: 0.7464 - val_acc: 0.6439\n",
      "Epoch 13/150\n",
      "644987/644987 [==============================] - 2s 4us/step - loss: 0.7489 - acc: 0.6401 - val_loss: 0.7473 - val_acc: 0.6425\n",
      "Epoch 14/150\n",
      "644987/644987 [==============================] - 2s 4us/step - loss: 0.7479 - acc: 0.6404 - val_loss: 0.7437 - val_acc: 0.6444\n",
      "Epoch 15/150\n",
      "644987/644987 [==============================] - 2s 4us/step - loss: 0.7470 - acc: 0.6411 - val_loss: 0.7544 - val_acc: 0.6363\n",
      "Epoch 16/150\n",
      "644987/644987 [==============================] - 2s 4us/step - loss: 0.7453 - acc: 0.6422 - val_loss: 0.7398 - val_acc: 0.6468\n",
      "Epoch 17/150\n",
      "644987/644987 [==============================] - 2s 4us/step - loss: 0.7434 - acc: 0.6432 - val_loss: 0.7412 - val_acc: 0.6440\n",
      "Epoch 18/150\n",
      "644987/644987 [==============================] - 2s 4us/step - loss: 0.7437 - acc: 0.6427 - val_loss: 0.7427 - val_acc: 0.6450\n",
      "Epoch 19/150\n",
      "644987/644987 [==============================] - 2s 4us/step - loss: 0.7424 - acc: 0.6437 - val_loss: 0.7464 - val_acc: 0.6419\n",
      "Epoch 20/150\n",
      "644987/644987 [==============================] - 2s 4us/step - loss: 0.7414 - acc: 0.6447 - val_loss: 0.7403 - val_acc: 0.6459\n",
      "Epoch 21/150\n",
      "644987/644987 [==============================] - 2s 4us/step - loss: 0.7410 - acc: 0.6443 - val_loss: 0.7428 - val_acc: 0.6456\n",
      "Epoch 22/150\n",
      "644987/644987 [==============================] - 2s 4us/step - loss: 0.7407 - acc: 0.6445 - val_loss: 0.7387 - val_acc: 0.6485\n",
      "Epoch 23/150\n",
      "644987/644987 [==============================] - 2s 4us/step - loss: 0.7408 - acc: 0.6457 - val_loss: 0.7410 - val_acc: 0.6437\n",
      "Epoch 24/150\n",
      "644987/644987 [==============================] - 2s 4us/step - loss: 0.7392 - acc: 0.6458 - val_loss: 0.7443 - val_acc: 0.6428\n",
      "Epoch 25/150\n",
      "644987/644987 [==============================] - 2s 4us/step - loss: 0.7388 - acc: 0.6463 - val_loss: 0.7452 - val_acc: 0.6457\n",
      "Epoch 26/150\n",
      "644987/644987 [==============================] - 2s 4us/step - loss: 0.7398 - acc: 0.6456 - val_loss: 0.7406 - val_acc: 0.6479\n",
      "Epoch 27/150\n",
      "644987/644987 [==============================] - 2s 4us/step - loss: 0.7383 - acc: 0.6470 - val_loss: 0.7400 - val_acc: 0.6446\n",
      "Epoch 28/150\n",
      "644987/644987 [==============================] - 2s 4us/step - loss: 0.7372 - acc: 0.6478 - val_loss: 0.7382 - val_acc: 0.6508\n",
      "Epoch 29/150\n",
      "644987/644987 [==============================] - 2s 4us/step - loss: 0.7375 - acc: 0.6472 - val_loss: 0.7378 - val_acc: 0.6501\n",
      "Epoch 30/150\n",
      "644987/644987 [==============================] - 2s 4us/step - loss: 0.7371 - acc: 0.6481 - val_loss: 0.7393 - val_acc: 0.6456\n",
      "Epoch 31/150\n",
      "644987/644987 [==============================] - 2s 4us/step - loss: 0.7369 - acc: 0.6471 - val_loss: 0.7380 - val_acc: 0.6463\n",
      "Epoch 32/150\n",
      "644987/644987 [==============================] - 2s 4us/step - loss: 0.7355 - acc: 0.6491 - val_loss: 0.7361 - val_acc: 0.6499\n",
      "Epoch 33/150\n",
      "644987/644987 [==============================] - 2s 4us/step - loss: 0.7351 - acc: 0.6499 - val_loss: 0.7324 - val_acc: 0.6536\n",
      "Epoch 34/150\n",
      "644987/644987 [==============================] - 2s 4us/step - loss: 0.7351 - acc: 0.6507 - val_loss: 0.7388 - val_acc: 0.6525\n",
      "Epoch 35/150\n",
      "644987/644987 [==============================] - 2s 4us/step - loss: 0.7335 - acc: 0.6510 - val_loss: 0.7304 - val_acc: 0.6535\n",
      "Epoch 36/150\n",
      "644987/644987 [==============================] - 2s 4us/step - loss: 0.7328 - acc: 0.6520 - val_loss: 0.7376 - val_acc: 0.6539\n",
      "Epoch 37/150\n",
      "644987/644987 [==============================] - 2s 4us/step - loss: 0.7316 - acc: 0.6528 - val_loss: 0.7353 - val_acc: 0.6501\n",
      "Epoch 38/150\n",
      "644987/644987 [==============================] - 2s 4us/step - loss: 0.7304 - acc: 0.6545 - val_loss: 0.7288 - val_acc: 0.6564\n",
      "Epoch 39/150\n",
      "644987/644987 [==============================] - 2s 4us/step - loss: 0.7299 - acc: 0.6548 - val_loss: 0.7306 - val_acc: 0.6573\n",
      "Epoch 40/150\n",
      "644987/644987 [==============================] - 2s 4us/step - loss: 0.7290 - acc: 0.6556 - val_loss: 0.7298 - val_acc: 0.6553\n",
      "Epoch 41/150\n",
      "644987/644987 [==============================] - 2s 4us/step - loss: 0.7288 - acc: 0.6552 - val_loss: 0.7383 - val_acc: 0.6507\n",
      "Epoch 42/150\n",
      "644987/644987 [==============================] - 2s 4us/step - loss: 0.7280 - acc: 0.6559 - val_loss: 0.7256 - val_acc: 0.6610\n",
      "Epoch 43/150\n",
      "644987/644987 [==============================] - 2s 4us/step - loss: 0.7263 - acc: 0.6574 - val_loss: 0.7300 - val_acc: 0.6559\n",
      "Epoch 44/150\n",
      "644987/644987 [==============================] - 2s 4us/step - loss: 0.7259 - acc: 0.6576 - val_loss: 0.7241 - val_acc: 0.6596\n",
      "Epoch 45/150\n",
      "644987/644987 [==============================] - 2s 4us/step - loss: 0.7256 - acc: 0.6580 - val_loss: 0.7236 - val_acc: 0.6627\n",
      "Epoch 46/150\n",
      "644987/644987 [==============================] - 2s 4us/step - loss: 0.7245 - acc: 0.6587 - val_loss: 0.7295 - val_acc: 0.6578\n",
      "Epoch 47/150\n",
      "644987/644987 [==============================] - 2s 4us/step - loss: 0.7247 - acc: 0.6586 - val_loss: 0.7269 - val_acc: 0.6602\n",
      "Epoch 48/150\n",
      "644987/644987 [==============================] - 2s 4us/step - loss: 0.7242 - acc: 0.6587 - val_loss: 0.7233 - val_acc: 0.6637\n",
      "Epoch 49/150\n",
      "644987/644987 [==============================] - 2s 4us/step - loss: 0.7239 - acc: 0.6587 - val_loss: 0.7228 - val_acc: 0.6619\n",
      "Epoch 50/150\n",
      "644987/644987 [==============================] - 2s 4us/step - loss: 0.7241 - acc: 0.6589 - val_loss: 0.7262 - val_acc: 0.6607\n",
      "Epoch 51/150\n",
      "644987/644987 [==============================] - 2s 4us/step - loss: 0.7241 - acc: 0.6590 - val_loss: 0.7228 - val_acc: 0.6606\n",
      "Epoch 52/150\n",
      "644987/644987 [==============================] - 2s 4us/step - loss: 0.7229 - acc: 0.6597 - val_loss: 0.7241 - val_acc: 0.6623\n",
      "Epoch 53/150\n",
      "644987/644987 [==============================] - 2s 4us/step - loss: 0.7231 - acc: 0.6596 - val_loss: 0.7231 - val_acc: 0.6642\n",
      "Epoch 54/150\n",
      "644987/644987 [==============================] - 2s 4us/step - loss: 0.7222 - acc: 0.6604 - val_loss: 0.7234 - val_acc: 0.6623\n",
      "Epoch 55/150\n",
      "644987/644987 [==============================] - 2s 4us/step - loss: 0.7215 - acc: 0.6610 - val_loss: 0.7206 - val_acc: 0.6643\n",
      "Epoch 56/150\n",
      "644987/644987 [==============================] - 2s 4us/step - loss: 0.7217 - acc: 0.6608 - val_loss: 0.7242 - val_acc: 0.6628\n",
      "Epoch 57/150\n",
      "644987/644987 [==============================] - 2s 4us/step - loss: 0.7216 - acc: 0.6606 - val_loss: 0.7236 - val_acc: 0.6635\n",
      "Epoch 58/150\n",
      "644987/644987 [==============================] - 2s 4us/step - loss: 0.7204 - acc: 0.6612 - val_loss: 0.7215 - val_acc: 0.6651\n",
      "Epoch 59/150\n",
      "644987/644987 [==============================] - 2s 4us/step - loss: 0.7206 - acc: 0.6614 - val_loss: 0.7177 - val_acc: 0.6655\n",
      "Epoch 60/150\n",
      "644987/644987 [==============================] - 2s 4us/step - loss: 0.7206 - acc: 0.6615 - val_loss: 0.7182 - val_acc: 0.6653\n",
      "Epoch 61/150\n",
      "644987/644987 [==============================] - 2s 4us/step - loss: 0.7202 - acc: 0.6616 - val_loss: 0.7192 - val_acc: 0.6643\n",
      "Epoch 62/150\n",
      "644987/644987 [==============================] - 2s 4us/step - loss: 0.7194 - acc: 0.6623 - val_loss: 0.7223 - val_acc: 0.6643\n",
      "Epoch 63/150\n",
      "644987/644987 [==============================] - 2s 4us/step - loss: 0.7193 - acc: 0.6622 - val_loss: 0.7249 - val_acc: 0.6623\n",
      "Epoch 64/150\n",
      "644987/644987 [==============================] - 2s 4us/step - loss: 0.7199 - acc: 0.6621 - val_loss: 0.7199 - val_acc: 0.6636\n",
      "Epoch 65/150\n",
      "644987/644987 [==============================] - 2s 4us/step - loss: 0.7188 - acc: 0.6625 - val_loss: 0.7204 - val_acc: 0.6622\n",
      "Epoch 66/150\n",
      "644987/644987 [==============================] - 2s 4us/step - loss: 0.7188 - acc: 0.6628 - val_loss: 0.7146 - val_acc: 0.6669\n",
      "Epoch 67/150\n",
      "644987/644987 [==============================] - 2s 4us/step - loss: 0.7181 - acc: 0.6631 - val_loss: 0.7205 - val_acc: 0.6660\n",
      "Epoch 68/150\n",
      "644987/644987 [==============================] - 2s 4us/step - loss: 0.7178 - acc: 0.6636 - val_loss: 0.7206 - val_acc: 0.6625\n",
      "Epoch 69/150\n",
      "644987/644987 [==============================] - 2s 4us/step - loss: 0.7183 - acc: 0.6631 - val_loss: 0.7159 - val_acc: 0.6670\n",
      "Epoch 70/150\n",
      "644987/644987 [==============================] - 2s 4us/step - loss: 0.7171 - acc: 0.6640 - val_loss: 0.7170 - val_acc: 0.6676\n",
      "Epoch 71/150\n",
      "644987/644987 [==============================] - 2s 4us/step - loss: 0.7169 - acc: 0.6640 - val_loss: 0.7157 - val_acc: 0.6685\n",
      "Epoch 72/150\n",
      "644987/644987 [==============================] - 2s 4us/step - loss: 0.7165 - acc: 0.6645 - val_loss: 0.7157 - val_acc: 0.6681\n",
      "Epoch 73/150\n",
      "644987/644987 [==============================] - 2s 4us/step - loss: 0.7170 - acc: 0.6638 - val_loss: 0.7171 - val_acc: 0.6677\n",
      "Epoch 74/150\n",
      "644987/644987 [==============================] - 2s 4us/step - loss: 0.7162 - acc: 0.6643 - val_loss: 0.7138 - val_acc: 0.6682\n",
      "Epoch 75/150\n",
      "644987/644987 [==============================] - 2s 4us/step - loss: 0.7161 - acc: 0.6647 - val_loss: 0.7163 - val_acc: 0.6652\n",
      "Epoch 76/150\n",
      "644987/644987 [==============================] - 2s 4us/step - loss: 0.7154 - acc: 0.6650 - val_loss: 0.7154 - val_acc: 0.6653\n",
      "Epoch 77/150\n",
      "644987/644987 [==============================] - 2s 4us/step - loss: 0.7155 - acc: 0.6651 - val_loss: 0.7161 - val_acc: 0.6671\n",
      "Epoch 78/150\n",
      "644987/644987 [==============================] - 2s 4us/step - loss: 0.7154 - acc: 0.6649 - val_loss: 0.7151 - val_acc: 0.6701\n",
      "Epoch 79/150\n",
      "644987/644987 [==============================] - 2s 4us/step - loss: 0.7148 - acc: 0.6648 - val_loss: 0.7133 - val_acc: 0.6665\n",
      "Epoch 80/150\n",
      "644987/644987 [==============================] - 2s 4us/step - loss: 0.7142 - acc: 0.6659 - val_loss: 0.7146 - val_acc: 0.6704\n",
      "Epoch 81/150\n",
      "644987/644987 [==============================] - 2s 4us/step - loss: 0.7142 - acc: 0.6660 - val_loss: 0.7126 - val_acc: 0.6691\n",
      "Epoch 82/150\n",
      "644987/644987 [==============================] - 2s 4us/step - loss: 0.7138 - acc: 0.6664 - val_loss: 0.7141 - val_acc: 0.6681\n",
      "Epoch 83/150\n",
      "644987/644987 [==============================] - 2s 4us/step - loss: 0.7140 - acc: 0.6661 - val_loss: 0.7149 - val_acc: 0.6701\n",
      "Epoch 84/150\n",
      "644987/644987 [==============================] - 2s 4us/step - loss: 0.7131 - acc: 0.6666 - val_loss: 0.7115 - val_acc: 0.6715\n",
      "Epoch 85/150\n",
      "644987/644987 [==============================] - 2s 4us/step - loss: 0.7137 - acc: 0.6664 - val_loss: 0.7150 - val_acc: 0.6657\n",
      "Epoch 86/150\n",
      "644987/644987 [==============================] - 2s 4us/step - loss: 0.7130 - acc: 0.6665 - val_loss: 0.7141 - val_acc: 0.6709\n",
      "Epoch 87/150\n",
      "644987/644987 [==============================] - 2s 4us/step - loss: 0.7128 - acc: 0.6666 - val_loss: 0.7097 - val_acc: 0.6723\n",
      "Epoch 88/150\n",
      "644987/644987 [==============================] - 2s 4us/step - loss: 0.7122 - acc: 0.6669 - val_loss: 0.7111 - val_acc: 0.6698\n",
      "Epoch 89/150\n",
      "644987/644987 [==============================] - 2s 4us/step - loss: 0.7123 - acc: 0.6673 - val_loss: 0.7098 - val_acc: 0.6722\n",
      "Epoch 90/150\n",
      "644987/644987 [==============================] - 2s 4us/step - loss: 0.7120 - acc: 0.6676 - val_loss: 0.7123 - val_acc: 0.6712\n",
      "Epoch 91/150\n",
      "644987/644987 [==============================] - 3s 4us/step - loss: 0.7115 - acc: 0.6675 - val_loss: 0.7084 - val_acc: 0.6730\n",
      "Epoch 92/150\n",
      "644987/644987 [==============================] - 2s 4us/step - loss: 0.7114 - acc: 0.6675 - val_loss: 0.7100 - val_acc: 0.6734\n",
      "Epoch 93/150\n",
      "644987/644987 [==============================] - 2s 4us/step - loss: 0.7112 - acc: 0.6677 - val_loss: 0.7094 - val_acc: 0.6734\n",
      "Epoch 94/150\n",
      "644987/644987 [==============================] - 2s 4us/step - loss: 0.7109 - acc: 0.6681 - val_loss: 0.7081 - val_acc: 0.6721\n",
      "Epoch 95/150\n",
      "644987/644987 [==============================] - 3s 4us/step - loss: 0.7110 - acc: 0.6680 - val_loss: 0.7078 - val_acc: 0.6722\n",
      "Epoch 96/150\n",
      "644987/644987 [==============================] - 2s 4us/step - loss: 0.7103 - acc: 0.6682 - val_loss: 0.7076 - val_acc: 0.6704\n",
      "Epoch 97/150\n",
      "644987/644987 [==============================] - 2s 4us/step - loss: 0.7103 - acc: 0.6683 - val_loss: 0.7088 - val_acc: 0.6720\n",
      "Epoch 98/150\n",
      "644987/644987 [==============================] - 2s 4us/step - loss: 0.7102 - acc: 0.6679 - val_loss: 0.7077 - val_acc: 0.6734\n",
      "Epoch 99/150\n",
      "644987/644987 [==============================] - 2s 4us/step - loss: 0.7093 - acc: 0.6687 - val_loss: 0.7066 - val_acc: 0.6750\n",
      "Epoch 100/150\n",
      "644987/644987 [==============================] - 2s 4us/step - loss: 0.7094 - acc: 0.6690 - val_loss: 0.7052 - val_acc: 0.6760\n",
      "Epoch 101/150\n",
      "644987/644987 [==============================] - 2s 4us/step - loss: 0.7094 - acc: 0.6690 - val_loss: 0.7054 - val_acc: 0.6735\n",
      "Epoch 102/150\n",
      "644987/644987 [==============================] - 2s 4us/step - loss: 0.7089 - acc: 0.6692 - val_loss: 0.7068 - val_acc: 0.6722\n",
      "Epoch 103/150\n",
      "644987/644987 [==============================] - 2s 4us/step - loss: 0.7093 - acc: 0.6690 - val_loss: 0.7059 - val_acc: 0.6755\n",
      "Epoch 104/150\n",
      "644987/644987 [==============================] - 3s 4us/step - loss: 0.7091 - acc: 0.6686 - val_loss: 0.7070 - val_acc: 0.6737\n",
      "Epoch 105/150\n",
      "644987/644987 [==============================] - 3s 4us/step - loss: 0.7084 - acc: 0.6692 - val_loss: 0.7030 - val_acc: 0.6747\n",
      "Epoch 106/150\n",
      "644987/644987 [==============================] - 2s 4us/step - loss: 0.7079 - acc: 0.6691 - val_loss: 0.7042 - val_acc: 0.6757\n",
      "Epoch 107/150\n",
      "644987/644987 [==============================] - 2s 4us/step - loss: 0.7087 - acc: 0.6692 - val_loss: 0.7038 - val_acc: 0.6755\n",
      "Epoch 108/150\n",
      "644987/644987 [==============================] - 2s 4us/step - loss: 0.7077 - acc: 0.6698 - val_loss: 0.7068 - val_acc: 0.6737\n",
      "Epoch 109/150\n",
      "644987/644987 [==============================] - 2s 4us/step - loss: 0.7077 - acc: 0.6699 - val_loss: 0.7033 - val_acc: 0.6766\n",
      "Epoch 110/150\n",
      "644987/644987 [==============================] - 2s 4us/step - loss: 0.7076 - acc: 0.6702 - val_loss: 0.7076 - val_acc: 0.6750\n",
      "Epoch 111/150\n",
      "644987/644987 [==============================] - 2s 4us/step - loss: 0.7069 - acc: 0.6702 - val_loss: 0.7034 - val_acc: 0.6754\n",
      "Epoch 112/150\n",
      "644987/644987 [==============================] - 3s 4us/step - loss: 0.7070 - acc: 0.6705 - val_loss: 0.7042 - val_acc: 0.6734\n",
      "Epoch 113/150\n",
      "644987/644987 [==============================] - 3s 4us/step - loss: 0.7065 - acc: 0.6702 - val_loss: 0.7033 - val_acc: 0.6754\n",
      "Epoch 114/150\n",
      "644987/644987 [==============================] - 3s 4us/step - loss: 0.7067 - acc: 0.6701 - val_loss: 0.7032 - val_acc: 0.6751\n",
      "Epoch 115/150\n",
      "644987/644987 [==============================] - 3s 4us/step - loss: 0.7065 - acc: 0.6704 - val_loss: 0.7029 - val_acc: 0.6757\n",
      "Epoch 116/150\n",
      "644987/644987 [==============================] - 3s 4us/step - loss: 0.7061 - acc: 0.6708 - val_loss: 0.7030 - val_acc: 0.6762\n",
      "Epoch 117/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "644987/644987 [==============================] - 2s 4us/step - loss: 0.7064 - acc: 0.6708 - val_loss: 0.7030 - val_acc: 0.6743\n",
      "Epoch 118/150\n",
      "644987/644987 [==============================] - 2s 4us/step - loss: 0.7054 - acc: 0.6709 - val_loss: 0.7016 - val_acc: 0.6776\n",
      "Epoch 119/150\n",
      "644987/644987 [==============================] - 2s 4us/step - loss: 0.7054 - acc: 0.6710 - val_loss: 0.7034 - val_acc: 0.6744\n",
      "Epoch 120/150\n",
      "644987/644987 [==============================] - 2s 4us/step - loss: 0.7053 - acc: 0.6709 - val_loss: 0.7002 - val_acc: 0.6759\n",
      "Epoch 121/150\n",
      "644987/644987 [==============================] - 2s 4us/step - loss: 0.7052 - acc: 0.6717 - val_loss: 0.7012 - val_acc: 0.6759\n",
      "Epoch 122/150\n",
      "644987/644987 [==============================] - 2s 4us/step - loss: 0.7053 - acc: 0.6714 - val_loss: 0.7003 - val_acc: 0.6783\n",
      "Epoch 123/150\n",
      "644987/644987 [==============================] - 2s 4us/step - loss: 0.7046 - acc: 0.6713 - val_loss: 0.6997 - val_acc: 0.6768\n",
      "Epoch 124/150\n",
      "644987/644987 [==============================] - 2s 4us/step - loss: 0.7040 - acc: 0.6718 - val_loss: 0.7004 - val_acc: 0.6778\n",
      "Epoch 125/150\n",
      "644987/644987 [==============================] - 2s 4us/step - loss: 0.7046 - acc: 0.6713 - val_loss: 0.6998 - val_acc: 0.6790\n",
      "Epoch 126/150\n",
      "644987/644987 [==============================] - 2s 4us/step - loss: 0.7042 - acc: 0.6718 - val_loss: 0.7004 - val_acc: 0.6759\n",
      "Epoch 127/150\n",
      "644987/644987 [==============================] - 2s 4us/step - loss: 0.7045 - acc: 0.6715 - val_loss: 0.7018 - val_acc: 0.6765\n",
      "Epoch 128/150\n",
      "644987/644987 [==============================] - 2s 4us/step - loss: 0.7041 - acc: 0.6716 - val_loss: 0.7022 - val_acc: 0.6758\n",
      "Epoch 129/150\n",
      "644987/644987 [==============================] - 2s 4us/step - loss: 0.7035 - acc: 0.6724 - val_loss: 0.6994 - val_acc: 0.6768\n",
      "Epoch 130/150\n",
      "644987/644987 [==============================] - 2s 4us/step - loss: 0.7034 - acc: 0.6722 - val_loss: 0.6999 - val_acc: 0.6754\n",
      "Epoch 131/150\n",
      "644987/644987 [==============================] - 3s 4us/step - loss: 0.7033 - acc: 0.6725 - val_loss: 0.6988 - val_acc: 0.6768\n",
      "Epoch 132/150\n",
      "644987/644987 [==============================] - 3s 4us/step - loss: 0.7030 - acc: 0.6724 - val_loss: 0.7011 - val_acc: 0.6766\n",
      "Epoch 133/150\n",
      "644987/644987 [==============================] - 3s 4us/step - loss: 0.7030 - acc: 0.6723 - val_loss: 0.7021 - val_acc: 0.6762\n",
      "Epoch 134/150\n",
      "644987/644987 [==============================] - 3s 4us/step - loss: 0.7026 - acc: 0.6725 - val_loss: 0.6991 - val_acc: 0.6796\n",
      "Epoch 135/150\n",
      "644987/644987 [==============================] - 3s 4us/step - loss: 0.7029 - acc: 0.6729 - val_loss: 0.6992 - val_acc: 0.6790\n",
      "Epoch 136/150\n",
      "644987/644987 [==============================] - 3s 4us/step - loss: 0.7017 - acc: 0.6730 - val_loss: 0.6966 - val_acc: 0.6804\n",
      "Epoch 137/150\n",
      "644987/644987 [==============================] - 3s 4us/step - loss: 0.7025 - acc: 0.6730 - val_loss: 0.7001 - val_acc: 0.6777\n",
      "Epoch 138/150\n",
      "644987/644987 [==============================] - 3s 4us/step - loss: 0.7023 - acc: 0.6726 - val_loss: 0.6980 - val_acc: 0.6783\n",
      "Epoch 139/150\n",
      "644987/644987 [==============================] - 3s 4us/step - loss: 0.7022 - acc: 0.6728 - val_loss: 0.7010 - val_acc: 0.6773\n",
      "Epoch 140/150\n",
      "644987/644987 [==============================] - 3s 4us/step - loss: 0.7018 - acc: 0.6728 - val_loss: 0.6996 - val_acc: 0.6759\n",
      "Epoch 141/150\n",
      "644987/644987 [==============================] - 3s 4us/step - loss: 0.7010 - acc: 0.6734 - val_loss: 0.6971 - val_acc: 0.6784\n",
      "Epoch 142/150\n",
      "644987/644987 [==============================] - 3s 4us/step - loss: 0.7011 - acc: 0.6733 - val_loss: 0.6964 - val_acc: 0.6783\n",
      "Epoch 143/150\n",
      "644987/644987 [==============================] - 3s 4us/step - loss: 0.7010 - acc: 0.6732 - val_loss: 0.6986 - val_acc: 0.6793\n",
      "Epoch 144/150\n",
      "644987/644987 [==============================] - 3s 4us/step - loss: 0.7008 - acc: 0.6737 - val_loss: 0.6979 - val_acc: 0.6796\n",
      "Epoch 145/150\n",
      "644987/644987 [==============================] - 3s 4us/step - loss: 0.7010 - acc: 0.6734 - val_loss: 0.6986 - val_acc: 0.6780\n",
      "Epoch 146/150\n",
      "644987/644987 [==============================] - 3s 4us/step - loss: 0.7007 - acc: 0.6735 - val_loss: 0.6972 - val_acc: 0.6804\n",
      "Epoch 147/150\n",
      "644987/644987 [==============================] - 3s 4us/step - loss: 0.7005 - acc: 0.6738 - val_loss: 0.6964 - val_acc: 0.6793\n",
      "Epoch 148/150\n",
      "644987/644987 [==============================] - 3s 4us/step - loss: 0.7002 - acc: 0.6736 - val_loss: 0.6979 - val_acc: 0.6794\n",
      "Epoch 149/150\n",
      "644987/644987 [==============================] - 3s 4us/step - loss: 0.7004 - acc: 0.6739 - val_loss: 0.6976 - val_acc: 0.6793\n",
      "Epoch 150/150\n",
      "644987/644987 [==============================] - 3s 4us/step - loss: 0.6999 - acc: 0.6741 - val_loss: 0.6963 - val_acc: 0.6804\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "enc = OneHotEncoder()\n",
    "enc.fit(y.reshape(-1, 1))\n",
    "y_hot = enc.transform(y.reshape(-1, 1))\n",
    "\n",
    "\n",
    "#构建LM神经网络模型\n",
    "from keras.models import Sequential #导入神经网络初始化函数\n",
    "from keras.layers.core import Dense, Activation #导入神经网络层函数、激活函数\n",
    "from keras.layers import Dropout\n",
    "from keras.metrics import top_k_categorical_accuracy\n",
    "from keras.callbacks import EarlyStopping\n",
    "netfile = './net.model' #构建的神经网络模型存储路径\n",
    "\n",
    "def acc_top2(y_true, y_pred):\n",
    "    return top_k_categorical_accuracy(y_true, y_pred, k=2)\n",
    "\n",
    "net = Sequential()\n",
    "net.add(Dense(input_dim = 38, output_dim = 128))\n",
    "net.add(Activation('relu'))\n",
    "net.add(Dense(input_dim = 128, output_dim = 256))\n",
    "net.add(Activation('relu'))\n",
    "net.add(Dense(input_dim = 256, output_dim = 256))\n",
    "net.add(Activation('relu'))\n",
    "net.add(Dropout(0.3))\n",
    "net.add(Dense(input_dim = 256, output_dim = 512))\n",
    "net.add(Activation('relu'))\n",
    "net.add(Dense(input_dim = 512, output_dim = 4))\n",
    "net.add(Activation('softmax'))\n",
    "net.compile(loss = 'categorical_crossentropy', optimizer = 'adam', metrics=['accuracy']) # accuracy\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=50, verbose=2)\n",
    "\n",
    "net.fit(train, y_hot, epochs=150, batch_size=4096, validation_data=(train[600000:], y_hot[600000:]), callbacks=[early_stopping])\n",
    "net.save_weights(netfile) #保存模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.775790784004\n"
     ]
    }
   ],
   "source": [
    "predict_prob = net.predict_proba(train[600000:])\n",
    "pb = np.array(predict_prob)\n",
    "submit = pd.DataFrame()\n",
    "submit['y1'] = pb.argsort()[np.arange(len(pb)), -1]\n",
    "submit['y2'] = pb.argsort()[np.arange(len(pb)), -2]\n",
    "print(test_score(submit['y1'].values, submit['y2'].values, y[600000:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predict_prob = net.predict_proba(test)\n",
    "pb = np.array(predict_prob)\n",
    "nn_submit = pd.DataFrame()\n",
    "nn_submit['y1'] = pb.argsort()[np.arange(len(pb)), -1]\n",
    "nn_submit['y2'] = pb.argsort()[np.arange(len(pb)), -2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "xgb_submit.to_csv('xgb_subumit.csv', index=False)\n",
    "lgb_submit.to_csv('lgb_submit.csv', index=False)\n",
    "nn_submit.to_csv('nn_submit.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def wsubmit(xg, lg, nn):\n",
    "    xg_y1 = xg['y1'].values\n",
    "    lg_y1 = lg['y1'].values\n",
    "    lg_y2 = lg['y2'].values\n",
    "    nn_y1 = lg['y1'].values\n",
    "    submitData = pd.DataFrame()\n",
    "    y1 = []\n",
    "    y2 = []\n",
    "    for i in range(len(xg)):\n",
    "        row_y1 = [xg_y1[i], lg_y1[i], nn_y1[i]]\n",
    "        y1.append(max(row_y1, key=row_y1.count))\n",
    "        if max(row_y1, key=row_y1.count) != lg_y1[i]:\n",
    "            y2.append(lg_y1[i])\n",
    "        else:\n",
    "            y2.append(lg_y2[i])\n",
    "    submitData['y1'] = y1\n",
    "    submitData['y2'] = y2\n",
    "    submitData.to_csv('submit_voting.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "wsubmit(xgb_submit, lgb_submit, nn_submit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 混合"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(train, y, test_size=0.2, random_state=0)##test_size测试集合所占比例\n",
    "##X_train_1用于生成模型  X_train_2用于和新特征组成新训练集合\n",
    "X_train_1, X_train_2, y_train_1, y_train_2 = train_test_split(X_train, y_train, test_size=0.7, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def mergeToOne(X,X2):\n",
    "    return np.hstack((X, X2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "from xgboost.sklearn import XGBClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "xgb = XGBClassifier(booster='gbtree', \n",
    "                    learning_rate =0.1,\n",
    "                    objective='multi:softmax', \n",
    "                    num_class=4, \n",
    "                    gamma=0.05, \n",
    "                    subsample=0.4, \n",
    "                    reg_alpha=1e-05,\n",
    "                    n_estimators=50,\n",
    "                    metric='multi_logloss',\n",
    "                    colsample_bytree=0.7, \n",
    "                    silent=1, \n",
    "                    nthread=4)\n",
    "\n",
    "gbm = lgb.LGBMClassifier(learning_rate=0.1, \n",
    "                   boosting_type='gbdt', \n",
    "                   objective='multiclass',\n",
    "                   n_estimators=50,\n",
    "                   metric='multi_logloss', \n",
    "                   max_depth=7, \n",
    "                   bagging_fraction=0.7, \n",
    "                   is_unbalance=True)\n",
    "\n",
    "rf = RandomForestClassifier(n_estimators=50, \n",
    "                            min_samples_split=90, \n",
    "                            min_samples_leaf=15,\n",
    "                            max_depth=8,\n",
    "                            oob_score=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "xgb.fit(X_train_1, y_train_1)\n",
    "new_feature= xgb.apply(X_train_2)\n",
    "\n",
    "X_train_new2 = mergeToOne(X_train_2,new_feature)\n",
    "new_feature_test = xgb.apply(X_test)\n",
    "X_test_new = mergeToOne(X_test,new_feature_test)\n",
    "# real_test_xgb = xgb.apply(test)\n",
    "# real_test = mergeToOne(test, real_test_xgb)\n",
    "\n",
    "gbm.fit(X_train_1, y_train_1)\n",
    "new_feature = gbm.apply(X_train_2)\n",
    "\n",
    "X_train_new2 = mergeToOne(X_train_new2,new_feature)\n",
    "new_feature_test = gbm.apply(X_test)\n",
    "X_test_new = mergeToOne(X_test_new,new_feature_test)\n",
    "# real_test_lgb = gbm.apply(test)\n",
    "# real_test = mergeToOne(real_test, real_test_lgb)\n",
    "\n",
    "rf.fit(X_train_1, y_train_1)\n",
    "new_feature = rf.apply(X_train_2)\n",
    "X_train_new2 = mergeToOne(X_train_new2, new_feature)\n",
    "new_feature_test = rf.apply(X_test)\n",
    "X_test_new = mergeToOne(X_test_new, new_feature_test)\n",
    "# real_test_lgb = rf.apply(test)\n",
    "# real_test = mergeToOne(real_test, real_test_lgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train_new2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train_new2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "enc = OneHotEncoder()\n",
    "# enc.fit(y.reshape(-1, 1))\n",
    "# y = enc.transform(y.reshape(-1, 1))\n",
    "enc.fit(y_train_2.reshape(-1, 1))\n",
    "y_train_2 = enc.transform(y_train_2.reshape(-1, 1)).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#构建LM神经网络模型\n",
    "from keras.models import Sequential #导入神经网络初始化函数\n",
    "from keras.layers.core import Dense, Activation #导入神经网络层函数、激活函数\n",
    "from keras.layers import Dropout\n",
    "from keras.callbacks import EarlyStopping\n",
    "netfile = './net.model' #构建的神经网络模型存储路径\n",
    "\n",
    "\n",
    "net = Sequential()\n",
    "net.add(Dense(input_dim = 472, output_dim = 128))\n",
    "net.add(Activation('relu'))\n",
    "net.add(Dense(input_dim = 128, output_dim = 256))\n",
    "net.add(Activation('relu'))\n",
    "net.add(Dense(input_dim = 256, output_dim = 256))\n",
    "net.add(Activation('relu'))\n",
    "net.add(Dropout(0.3))\n",
    "net.add(Dense(input_dim = 256, output_dim = 512))\n",
    "net.add(Activation('relu'))\n",
    "net.add(Dense(input_dim = 512, output_dim = 4))\n",
    "net.add(Activation('softmax'))\n",
    "net.compile(loss = 'categorical_crossentropy', optimizer = 'adam', metrics=['accuracy'])\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=50, verbose=2)\n",
    "net.fit(X_train_new2, y_train_2, epochs=100, batch_size=4096, validation_data=(X_test_new, y_test), callbacks=[early_stopping])\n",
    "# net.fit(train, y, epochs=100, batch_size=4096)\n",
    "net.save_weights(netfile) #保存模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predict_prob = net.predict_proba(X_test_new)\n",
    "pb = np.array(predict_prob)\n",
    "submit = pd.DataFrame()\n",
    "submit['y1'] = pb.argsort()[np.arange(len(pb)), -1]\n",
    "submit['y2'] = pb.argsort()[np.arange(len(pb)), -2]\n",
    "print(test_score(submit['y1'].values, submit['y2'].values, y_test.values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
